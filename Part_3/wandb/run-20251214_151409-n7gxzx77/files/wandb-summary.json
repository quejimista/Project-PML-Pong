{"eval/mean_reward":-44982.707,"train/entropy_loss":0,"_runtime":929,"train/episode_length":1127,"_step":813,"train/clip_range":0.1,"_wandb":{"runtime":929},"global_step":475136,"_timestamp":1.7657225254381897e+09,"train/value_loss":1.709858e+06,"time/fps":558,"train/timesteps":465,"rollout/ep_len_mean":1127,"train/explained_variance":5.6684017e-05,"train/reward":-44975.007,"rollout/ep_rew_mean":-44983.188,"train/learning_rate":5e-05,"eval/mean_ep_length":1127,"train/policy_gradient_loss":2.6648195e-09,"train/approx_kl":0,"train/loss":1.8916346e+06,"train/clip_fraction":0}