
============================================================
Training PPO on ALE/Skiing-v5
============================================================

Saving TensorBoard logs to: C:/Pong_part_3/logs
Using cuda device

Model architecture:
ActorCriticCnnPolicy(
  (features_extractor): NatureCNN(
    (cnn): Sequential(
      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))
      (1): ReLU()
      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): ReLU()
      (6): Flatten(start_dim=1, end_dim=-1)
    )
    (linear): Sequential(
      (0): Linear(in_features=3136, out_features=512, bias=True)
      (1): ReLU()
    )
  )
  (pi_features_extractor): NatureCNN(
    (cnn): Sequential(
      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))
      (1): ReLU()
      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): ReLU()
      (6): Flatten(start_dim=1, end_dim=-1)
    )
    (linear): Sequential(
      (0): Linear(in_features=3136, out_features=512, bias=True)
      (1): ReLU()
    )
  )
  (vf_features_extractor): NatureCNN(
    (cnn): Sequential(
      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))
      (1): ReLU()
      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): ReLU()
      (6): Flatten(start_dim=1, end_dim=-1)
    )
    (linear): Sequential(
      (0): Linear(in_features=3136, out_features=512, bias=True)
      (1): ReLU()
    )
  )
  (mlp_extractor): MlpExtractor(
    (policy_net): Sequential()
    (value_net): Sequential()
  )
  (action_net): Linear(in_features=512, out_features=3, bias=True)
  (value_net): Linear(in_features=512, out_features=1, bias=True)
)

Starting training for 10,000,000 timesteps...
This equals 610 updates
Evaluation every 1250 updates
[34m[1mwandb[0m: [33mWARNING[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in C:/Pong_part_3/logs\PPO_3

Logging to C:/Pong_part_3/logs\PPO_3
C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x0000022EF48B5E80> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000022EB2A001A0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
[2Kwandb: WARNING Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom m [ [33m0:00:02[0m < [36m3:09:20[0m , [31m880 it/s[0m ]
metric to log your step values.
[2K---------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m16,336/10,000,000 [0m [ [33m0:00:20[0m < [36m3:22:36[0m , [31m821 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | -560     |
| time/              |          |
|    fps             | 804      |
|    iterations      | 1        |
|    time_elapsed    | 20       |
|    total_timesteps | 16384    |
---------------------------------
[2K-----------------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m32,680/10,000,000 [0m [ [33m0:00:51[0m < [36m4:16:22[0m , [31m648 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 362         |
|    ep_rew_mean          | -580        |
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 2           |
|    time_elapsed         | 51          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.001365778 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.1        |
|    explained_variance   | 3.16e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 44.7        |
|    n_updates            | 4           |
|    policy_gradient_loss | 0.00184     |
|    value_loss           | 127         |
-----------------------------------------
[2K------------------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m49,096/10,000,000 [0m [ [33m0:01:30[0m < [36m5:13:09[0m , [31m530 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 374          |
|    ep_rew_mean          | -596         |
| time/                   |              |
|    fps                  | 543          |
|    iterations           | 3            |
|    time_elapsed         | 90           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0064454097 |
|    clip_fraction        | 0.287        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.785        |
|    learning_rate        | 0.0001       |
|    loss                 | 23           |
|    n_updates            | 8            |
|    policy_gradient_loss | 0.00978      |
|    value_loss           | 44.4         |
------------------------------------------
[2K-----------------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m65,512/10,000,000 [0m [ [33m0:02:05[0m < [36m4:41:26[0m , [31m588 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 377         |
|    ep_rew_mean          | -600        |
| time/                   |             |
|    fps                  | 520         |
|    iterations           | 4           |
|    time_elapsed         | 125         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.009314149 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.0001      |
|    loss                 | 14.9        |
|    n_updates            | 12          |
|    policy_gradient_loss | 0.0197      |
|    value_loss           | 37.4        |
-----------------------------------------
[2KEval num_timesteps=80000, episode_reward=-563.55 +/- 66.13â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m79,992/10,000,000 [0m [ [33m0:03:04[0m < [36m10:15:08[0m , [31m269 it/s[0m ]
[2KEpisode length: 349.20 +/- 49.670m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m79,992/10,000,000 [0m [ [33m0:03:04[0m < [36m10:15:08[0m , [31m269 it/s[0m ]
[2K------------------------------------------37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m79,992/10,000,000 [0m [ [33m0:03:04[0m < [36m10:15:08[0m , [31m269 it/s[0m ]
| eval/                   |              |
|    mean_ep_length       | 349          |
|    mean_reward          | -564         |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0065813977 |
|    clip_fraction        | 0.313        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.08        |
|    explained_variance   | 0.18         |
|    learning_rate        | 0.0001       |
|    loss                 | 18           |
|    n_updates            | 16           |
|    policy_gradient_loss | 0.00957      |
|    value_loss           | 33.1         |
------------------------------------------
[2KNew best mean reward!;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m79,992/10,000,000 [0m [ [33m0:03:04[0m < [36m10:15:08[0m , [31m269 it/s[0m ]
[2K---------------------------------â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m81,880/10,000,000 [0m [ [33m0:03:06[0m < [36m24:30:47[0m , [31m112 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | -592     |
| time/              |          |
|    fps             | 437      |
|    iterations      | 5        |
|    time_elapsed    | 187      |
|    total_timesteps | 81920    |
---------------------------------
[2K------------------------------------------;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m98,184/10,000,000 [0m [ [33m0:03:33[0m < [36m4:17:49[0m , [31m640 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 369          |
|    ep_rew_mean          | -590         |
| time/                   |              |
|    fps                  | 461          |
|    iterations           | 6            |
|    time_elapsed         | 213          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0033584991 |
|    clip_fraction        | 0.181        |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.09        |
|    explained_variance   | -0.382       |
|    learning_rate        | 0.0001       |
|    loss                 | 24.9         |
|    n_updates            | 20           |
|    policy_gradient_loss | 0.00103      |
|    value_loss           | 41.2         |
------------------------------------------
[2K----------------------------------------38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m114,688/10,000,000 [0m [ [33m0:04:02[0m < [36m4:54:37[0m , [31m559 it/s[0m ]
| rollout/                |            |
|    ep_len_mean          | 435        |
|    ep_rew_mean          | -669       |
| time/                   |            |
|    fps                  | 472        |
|    iterations           | 7          |
|    time_elapsed         | 242        |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.47406453 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.1        |
|    entropy_loss         | -0.984     |
|    explained_variance   | 0.149      |
|    learning_rate        | 0.0001     |
|    loss                 | 26.4       |
|    n_updates            | 24         |
|    policy_gradient_loss | 0.0695     |
|    value_loss           | 55.5       |
----------------------------------------
[2K---------------------------------------[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m131,040/10,000,000 [0m [ [33m0:04:36[0m < [36m4:31:02[0m , [31m607 it/s[0m ]
| rollout/                |           |
|    ep_len_mean          | 374       |
|    ep_rew_mean          | -581      |
| time/                   |           |
|    fps                  | 473       |
|    iterations           | 8         |
|    time_elapsed         | 276       |
|    total_timesteps      | 131072    |
| train/                  |           |
|    approx_kl            | 1.5700417 |
|    clip_fraction        | 0.604     |
|    clip_range           | 0.1       |
|    entropy_loss         | -0.659    |
|    explained_variance   | 0.00801   |
|    learning_rate        | 0.0001    |
|    loss                 | 89.7      |
|    n_updates            | 28        |
|    policy_gradient_loss | 0.0407    |
|    value_loss           | 187       |
---------------------------------------
[2K-------------------------------------------5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m147,400/10,000,000 [0m [ [33m0:05:08[0m < [36m4:19:44[0m , [31m632 it/s[0m ]
| rollout/                |               |
|    ep_len_mean          | 214           |
|    ep_rew_mean          | -383          |
| time/                   |               |
|    fps                  | 477           |
|    iterations           | 9             |
|    time_elapsed         | 308           |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 0.00034513668 |
|    clip_fraction        | 0.0153        |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.118        |
|    explained_variance   | 0.232         |
|    learning_rate        | 0.0001        |
|    loss                 | 239           |
|    n_updates            | 32            |
|    policy_gradient_loss | 0.00125       |
|    value_loss           | 306           |
-------------------------------------------
[2KEval num_timesteps=160000, episode_reward=-407.79 +/- 109.57;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m159,920/10,000,000 [0m [ [33m0:05:46[0m < [36m4:56:17[0m , [31m554 it/s[0m ]
[2KEpisode length: 232.20 +/- 82.310m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m159,920/10,000,000 [0m [ [33m0:05:46[0m < [36m4:56:17[0m , [31m554 it/s[0m ]
[2K-----------------------------------------237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m159,920/10,000,000 [0m [ [33m0:05:46[0m < [36m4:56:17[0m , [31m554 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 232         |
|    mean_reward          | -408        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.001276982 |
|    clip_fraction        | 0.0154      |
|    clip_range           | 0.1         |
|    entropy_loss         | -0.14       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.0001      |
|    loss                 | 158         |
|    n_updates            | 36          |
|    policy_gradient_loss | 0.000807    |
|    value_loss           | 196         |
-----------------------------------------
[2KNew best mean reward!;38;114mâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m159,920/10,000,000 [0m [ [33m0:05:46[0m < [36m4:56:17[0m , [31m554 it/s[0m ]
[2K---------------------------------â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m163,776/10,000,000 [0m [ [33m0:05:51[0m < [36m7:03:41[0m , [31m387 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | -365     |
| time/              |          |
|    fps             | 465      |
|    iterations      | 10       |
|    time_elapsed    | 351      |
|    total_timesteps | 163840   |
---------------------------------
[2K------------------------------------------;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m180,160/10,000,000 [0m [ [33m0:06:17[0m < [36m4:08:31[0m , [31m659 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 216          |
|    ep_rew_mean          | -386         |
| time/                   |              |
|    fps                  | 477          |
|    iterations           | 11           |
|    time_elapsed         | 377          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0022188108 |
|    clip_fraction        | 0.017        |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.151       |
|    explained_variance   | 0.779        |
|    learning_rate        | 0.0001       |
|    loss                 | 151          |
|    n_updates            | 40           |
|    policy_gradient_loss | 0.000522     |
|    value_loss           | 229          |
------------------------------------------
[2K------------------------------------------;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m196,584/10,000,000 [0m [ [33m0:06:46[0m < [36m4:51:53[0m , [31m560 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | -433         |
| time/                   |              |
|    fps                  | 483          |
|    iterations           | 12           |
|    time_elapsed         | 406          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0021545892 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.186       |
|    explained_variance   | 0.84         |
|    learning_rate        | 0.0001       |
|    loss                 | 177          |
|    n_updates            | 44           |
|    policy_gradient_loss | 0.000317     |
|    value_loss           | 240          |
------------------------------------------
[2K-------------------------------------------5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m212,944/10,000,000 [0m [ [33m0:07:19[0m < [36m4:25:20[0m , [31m615 it/s[0m ]
| rollout/                |               |
|    ep_len_mean          | 276           |
|    ep_rew_mean          | -467          |
| time/                   |               |
|    fps                  | 484           |
|    iterations           | 13            |
|    time_elapsed         | 439           |
|    total_timesteps      | 212992        |
| train/                  |               |
|    approx_kl            | 0.00050864636 |
|    clip_fraction        | 0.0276        |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.233        |
|    explained_variance   | 0.89          |
|    learning_rate        | 0.0001        |
|    loss                 | 143           |
|    n_updates            | 48            |
|    policy_gradient_loss | 0.000666      |
|    value_loss           | 244           |
-------------------------------------------
[2K-------------------------------------------5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m229,264/10,000,000 [0m [ [33m0:07:52[0m < [36m4:03:12[0m , [31m670 it/s[0m ]
| rollout/                |               |
|    ep_len_mean          | 287           |
|    ep_rew_mean          | -481          |
| time/                   |               |
|    fps                  | 485           |
|    iterations           | 14            |
|    time_elapsed         | 472           |
|    total_timesteps      | 229376        |
| train/                  |               |
|    approx_kl            | 0.00097325497 |
|    clip_fraction        | 0.0292        |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.257        |
|    explained_variance   | 0.905         |
|    learning_rate        | 0.0001        |
|    loss                 | 204           |
|    n_updates            | 52            |
|    policy_gradient_loss | 0.000493      |
|    value_loss           | 249           |
-------------------------------------------
[2KEval num_timesteps=240000, episode_reward=-521.34 +/- 177.79m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m239,992/10,000,000 [0m [ [33m0:08:35[0m < [36m9:19:11[0m , [31m291 it/s[0m ]
[2KEpisode length: 317.50 +/- 133.55m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m239,992/10,000,000 [0m [ [33m0:08:35[0m < [36m9:19:11[0m , [31m291 it/s[0m ]
[2K------------------------------------------49;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m239,992/10,000,000 [0m [ [33m0:08:35[0m < [36m9:19:11[0m , [31m291 it/s[0m ]
| eval/                   |              |
|    mean_ep_length       | 318          |
|    mean_reward          | -521         |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0017438735 |
|    clip_fraction        | 0.043        |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.309       |
|    explained_variance   | 0.911        |
|    learning_rate        | 0.0001       |
|    loss                 | 219          |
|    n_updates            | 56           |
|    policy_gradient_loss | 2.32e-05     |
|    value_loss           | 234          |
------------------------------------------
[2K---------------------------------â”[0m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m245,672/10,000,000 [0m [ [33m0:08:42[0m < [36m10:36:20[0m , [31m255 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 290      |
|    ep_rew_mean     | -484     |
| time/              |          |
|    fps             | 470      |
|    iterations      | 15       |
|    time_elapsed    | 522      |
|    total_timesteps | 245760   |
---------------------------------
[2K------------------------------------------;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m262,104/10,000,000 [0m [ [33m0:09:14[0m < [36m4:12:47[0m , [31m642 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 277          |
|    ep_rew_mean          | -468         |
| time/                   |              |
|    fps                  | 472          |
|    iterations           | 16           |
|    time_elapsed         | 554          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0024686535 |
|    clip_fraction        | 0.0444       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.313       |
|    explained_variance   | 0.925        |
|    learning_rate        | 0.0001       |
|    loss                 | 294          |
|    n_updates            | 60           |
|    policy_gradient_loss | 0.000952     |
|    value_loss           | 301          |
------------------------------------------
[2K------------------------------------------;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m278,336/10,000,000 [0m [ [33m0:09:49[0m < [36m4:40:03[0m , [31m579 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 293          |
|    ep_rew_mean          | -488         |
| time/                   |              |
|    fps                  | 472          |
|    iterations           | 17           |
|    time_elapsed         | 589          |
|    total_timesteps      | 278528       |
| train/                  |              |
|    approx_kl            | 0.0010853267 |
|    clip_fraction        | 0.0427       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.313       |
|    explained_variance   | 0.936        |
|    learning_rate        | 0.0001       |
|    loss                 | 199          |
|    n_updates            | 64           |
|    policy_gradient_loss | 0.000859     |
|    value_loss           | 267          |
------------------------------------------
[2K------------------------------------------;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m294,848/10,000,000 [0m [ [33m0:10:19[0m < [36m4:51:09[0m , [31m556 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 298          |
|    ep_rew_mean          | -495         |
| time/                   |              |
|    fps                  | 476          |
|    iterations           | 18           |
|    time_elapsed         | 619          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0009995892 |
|    clip_fraction        | 0.0415       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.334       |
|    explained_variance   | 0.94         |
|    learning_rate        | 0.0001       |
|    loss                 | 265          |
|    n_updates            | 68           |
|    policy_gradient_loss | 0.00066      |
|    value_loss           | 304          |
------------------------------------------
[2K------------------------------------------;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m311,224/10,000,000 [0m [ [33m0:10:46[0m < [36m4:32:29[0m , [31m593 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 276          |
|    ep_rew_mean          | -465         |
| time/                   |              |
|    fps                  | 481          |
|    iterations           | 19           |
|    time_elapsed         | 646          |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 0.0018344141 |
|    clip_fraction        | 0.0441       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.34        |
|    explained_variance   | 0.95         |
|    learning_rate        | 0.0001       |
|    loss                 | 243          |
|    n_updates            | 72           |
|    policy_gradient_loss | 0.000722     |
|    value_loss           | 305          |
------------------------------------------
[2KEval num_timesteps=320000, episode_reward=-479.01 +/- 92.56;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m319,992/10,000,000 [0m [ [33m0:11:25[0m < [36m8:39:04[0m , [31m311 it/s[0m ]s[0m ]
[2KEpisode length: 285.70 +/- 69.53[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m319,992/10,000,000 [0m [ [33m0:11:25[0m < [36m8:39:04[0m , [31m311 it/s[0m ]
[2K------------------------------------------237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m319,992/10,000,000 [0m [ [33m0:11:25[0m < [36m8:39:04[0m , [31m311 it/s[0m ]
| eval/                   |              |
|    mean_ep_length       | 286          |
|    mean_reward          | -479         |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0016217344 |
|    clip_fraction        | 0.0446       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.343       |
|    explained_variance   | 0.951        |
|    learning_rate        | 0.0001       |
|    loss                 | 239          |
|    n_updates            | 76           |
|    policy_gradient_loss | 0.000547     |
|    value_loss           | 314          |
------------------------------------------
[2K---------------------------------â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m327,664/10,000,000 [0m [ [33m0:11:38[0m < [36m6:19:27[0m , [31m425 it/s[0m ]s[0m ]
| rollout/           |          |
|    ep_len_mean     | 269      |
|    ep_rew_mean     | -457     |
| time/              |          |
|    fps             | 469      |
|    iterations      | 20       |
|    time_elapsed    | 698      |
|    total_timesteps | 327680   |
---------------------------------
[2K-------------------------------------------;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m343,992/10,000,000 [0m [ [33m0:12:07[0m < [36m4:38:21[0m , [31m578 it/s[0m ]
| rollout/                |               |
|    ep_len_mean          | 280           |
|    ep_rew_mean          | -471          |
| time/                   |               |
|    fps                  | 472           |
|    iterations           | 21            |
|    time_elapsed         | 727           |
|    total_timesteps      | 344064        |
| train/                  |               |
|    approx_kl            | 0.00096202875 |
|    clip_fraction        | 0.0558        |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.363        |
|    explained_variance   | 0.956         |
|    learning_rate        | 0.0001        |
|    loss                 | 319           |
|    n_updates            | 80            |
|    policy_gradient_loss | 0.00159       |
|    value_loss           | 322           |
-------------------------------------------
[2K-----------------------------------------38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m360,384/10,000,000 [0m [ [33m0:12:46[0m < [36m5:05:06[0m , [31m527 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 287         |
|    ep_rew_mean          | -480        |
| time/                   |             |
|    fps                  | 470         |
|    iterations           | 22          |
|    time_elapsed         | 766         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.002863387 |
|    clip_fraction        | 0.0556      |
|    clip_range           | 0.1         |
|    entropy_loss         | -0.336      |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.0001      |
|    loss                 | 233         |
|    n_updates            | 84          |
|    policy_gradient_loss | 0.00121     |
|    value_loss           | 280         |
-----------------------------------------
[2K------------------------------------------8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m376,760/10,000,000 [0m [ [33m0:13:21[0m < [36m4:34:55[0m , [31m583 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 283          |
|    ep_rew_mean          | -474         |
| time/                   |              |
|    fps                  | 469          |
|    iterations           | 23           |
|    time_elapsed         | 802          |
|    total_timesteps      | 376832       |
| train/                  |              |
|    approx_kl            | 0.0016167453 |
|    clip_fraction        | 0.0639       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.325       |
|    explained_variance   | 0.959        |
|    learning_rate        | 0.0001       |
|    loss                 | 251          |
|    n_updates            | 88           |
|    policy_gradient_loss | 0.00186      |
|    value_loss           | 295          |
------------------------------------------
[2K------------------------------------------8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m393,144/10,000,000 [0m [ [33m0:13:53[0m < [36m3:56:33[0m , [31m677 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 271          |
|    ep_rew_mean          | -460         |
| time/                   |              |
|    fps                  | 471          |
|    iterations           | 24           |
|    time_elapsed         | 833          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0013066548 |
|    clip_fraction        | 0.0675       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.33        |
|    explained_variance   | 0.969        |
|    learning_rate        | 0.0001       |
|    loss                 | 155          |
|    n_updates            | 92           |
|    policy_gradient_loss | 0.00234      |
|    value_loss           | 229          |
------------------------------------------
[2KEval num_timesteps=400000, episode_reward=-459.57 +/- 101.370m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m399,992/10,000,000 [0m [ [33m0:14:35[0m < [36m4:57:40[0m , [31m538 it/s[0m ]
[2KEpisode length: 271.10 +/- 76.15[0m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m399,992/10,000,000 [0m [ [33m0:14:35[0m < [36m4:57:40[0m , [31m538 it/s[0m ]
[2K------------------------------------------249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m399,992/10,000,000 [0m [ [33m0:14:35[0m < [36m4:57:40[0m , [31m538 it/s[0m ]
| eval/                   |              |
|    mean_ep_length       | 271          |
|    mean_reward          | -460         |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0031901514 |
|    clip_fraction        | 0.0772       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.338       |
|    explained_variance   | 0.972        |
|    learning_rate        | 0.0001       |
|    loss                 | 206          |
|    n_updates            | 96           |
|    policy_gradient_loss | 0.00272      |
|    value_loss           | 244          |
------------------------------------------
[2K---------------------------------â”â”[0m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m409,528/10,000,000 [0m [ [33m0:14:47[0m < [36m3:21:47[0m , [31m792 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 277      |
|    ep_rew_mean     | -468     |
| time/              |          |
|    fps             | 461      |
|    iterations      | 25       |
|    time_elapsed    | 887      |
|    total_timesteps | 409600   |
---------------------------------
[2K------------------------------------------8;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m425,888/10,000,000 [0m [ [33m0:15:13[0m < [36m4:05:26[0m , [31m650 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 292          |
|    ep_rew_mean          | -487         |
| time/                   |              |
|    fps                  | 466          |
|    iterations           | 26           |
|    time_elapsed         | 913          |
|    total_timesteps      | 425984       |
| train/                  |              |
|    approx_kl            | 0.0071555534 |
|    clip_fraction        | 0.0987       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.328       |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.0001       |
|    loss                 | 204          |
|    n_updates            | 100          |
|    policy_gradient_loss | 0.0063       |
|    value_loss           | 237          |
------------------------------------------
[2K------------------------------------------8;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m442,328/10,000,000 [0m [ [33m0:15:46[0m < [36m4:15:45[0m , [31m623 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 276          |
|    ep_rew_mean          | -466         |
| time/                   |              |
|    fps                  | 467          |
|    iterations           | 27           |
|    time_elapsed         | 946          |
|    total_timesteps      | 442368       |
| train/                  |              |
|    approx_kl            | 0.0036657355 |
|    clip_fraction        | 0.0837       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.338       |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.0001       |
|    loss                 | 225          |
|    n_updates            | 104          |
|    policy_gradient_loss | 0.00096      |
|    value_loss           | 255          |
------------------------------------------
[2K------------------------------------------8;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m458,704/10,000,000 [0m [ [33m0:16:22[0m < [36m4:33:30[0m , [31m581 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 269          |
|    ep_rew_mean          | -457         |
| time/                   |              |
|    fps                  | 466          |
|    iterations           | 28           |
|    time_elapsed         | 982          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0010740906 |
|    clip_fraction        | 0.0625       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.35        |
|    explained_variance   | 0.977        |
|    learning_rate        | 0.0001       |
|    loss                 | 155          |
|    n_updates            | 108          |
|    policy_gradient_loss | 0.0024       |
|    value_loss           | 224          |
------------------------------------------
[2K-----------------------------------------38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m475,072/10,000,000 [0m [ [33m0:16:59[0m < [36m4:40:07[0m , [31m567 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 290         |
|    ep_rew_mean          | -484        |
| time/                   |             |
|    fps                  | 465         |
|    iterations           | 29          |
|    time_elapsed         | 1019        |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.005548481 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.1         |
|    entropy_loss         | -0.347      |
|    explained_variance   | 0.978       |
|    learning_rate        | 0.0001      |
|    loss                 | 162         |
|    n_updates            | 112         |
|    policy_gradient_loss | 0.00947     |
|    value_loss           | 233         |
-----------------------------------------
[2KEval num_timesteps=480000, episode_reward=-490.46 +/- 73.58[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m479,992/10,000,000 [0m [ [33m0:17:32[0m < [36m12:55:59[0m , [31m204 it/s[0m ]
[2KEpisode length: 294.30 +/- 55.27[0m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m479,992/10,000,000 [0m [ [33m0:17:32[0m < [36m12:55:59[0m , [31m204 it/s[0m ]
[2K-----------------------------------------;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m479,992/10,000,000 [0m [ [33m0:17:32[0m < [36m12:55:59[0m , [31m204 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 294         |
|    mean_reward          | -490        |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.013049736 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.1         |
|    entropy_loss         | -0.357      |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.0001      |
|    loss                 | 277         |
|    n_updates            | 116         |
|    policy_gradient_loss | 0.00709     |
|    value_loss           | 247         |
-----------------------------------------
[2K---------------------------------â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m491,480/10,000,000 [0m [ [33m0:17:52[0m < [36m5:01:40[0m , [31m525 it/s[0m ]s[0m ]
| rollout/           |          |
|    ep_len_mean     | 288      |
|    ep_rew_mean     | -482     |
| time/              |          |
|    fps             | 458      |
|    iterations      | 30       |
|    time_elapsed    | 1072     |
|    total_timesteps | 491520   |
---------------------------------
[2K------------------------------------------38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m507,872/10,000,000 [0m [ [33m0:18:30[0m < [36m4:50:36[0m , [31m544 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 274          |
|    ep_rew_mean          | -464         |
| time/                   |              |
|    fps                  | 457          |
|    iterations           | 31           |
|    time_elapsed         | 1110         |
|    total_timesteps      | 507904       |
| train/                  |              |
|    approx_kl            | 0.0037400355 |
|    clip_fraction        | 0.0803       |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.273       |
|    explained_variance   | 0.974        |
|    learning_rate        | 0.0001       |
|    loss                 | 211          |
|    n_updates            | 120          |
|    policy_gradient_loss | 0.00232      |
|    value_loss           | 210          |
------------------------------------------
[2K-----------------------------------------[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m524,232/10,000,000 [0m [ [33m0:19:07[0m < [36m4:39:20[0m , [31m565 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 343         |
|    ep_rew_mean          | -546        |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 32          |
|    time_elapsed         | 1147        |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.027570564 |
|    clip_fraction        | 0.0949      |
|    clip_range           | 0.1         |
|    entropy_loss         | -0.293      |
|    explained_variance   | 0.976       |
|    learning_rate        | 0.0001      |
|    loss                 | 213         |
|    n_updates            | 124         |
|    policy_gradient_loss | 0.0065      |
|    value_loss           | 232         |
-----------------------------------------
[2K----------------------------------------[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m540,528/10,000,000 [0m [ [33m0:19:43[0m < [36m4:36:48[0m , [31m570 it/s[0m ]
| rollout/                |            |
|    ep_len_mean          | 467        |
|    ep_rew_mean          | -702       |
| time/                   |            |
|    fps                  | 456        |
|    iterations           | 33         |
|    time_elapsed         | 1184       |
|    total_timesteps      | 540672     |
| train/                  |            |
|    approx_kl            | 0.07796088 |
|    clip_fraction        | 0.733      |
|    clip_range           | 0.1        |
|    entropy_loss         | -0.542     |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.0001     |
|    loss                 | 421        |
|    n_updates            | 128        |
|    policy_gradient_loss | 0.0339     |
|    value_loss           | 948        |
----------------------------------------
[2K----------------------------------------[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m556,928/10,000,000 [0m [ [33m0:20:10[0m < [36m4:15:28[0m , [31m616 it/s[0m ]
| rollout/                |            |
|    ep_len_mean          | 422        |
|    ep_rew_mean          | -647       |
| time/                   |            |
|    fps                  | 460        |
|    iterations           | 34         |
|    time_elapsed         | 1210       |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.01724804 |
|    clip_fraction        | 0.151      |
|    clip_range           | 0.1        |
|    entropy_loss         | -0.275     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.0001     |
|    loss                 | 1.64e+03   |
|    n_updates            | 132        |
|    policy_gradient_loss | 0.0058     |
|    value_loss           | 1.05e+03   |
----------------------------------------
[2KEval num_timesteps=560000, episode_reward=-430.95 +/- 142.12[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m559,944/10,000,000 [0m [ [33m0:20:39[0m < [36m4:49:13[0m , [31m544 it/s[0m ]
[2KEpisode length: 249.60 +/- 106.75[0m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m559,944/10,000,000 [0m [ [33m0:20:39[0m < [36m4:49:13[0m , [31m544 it/s[0m ]
[2K------------------------------------------;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m559,944/10,000,000 [0m [ [33m0:20:39[0m < [36m4:49:13[0m , [31m544 it/s[0m ]
| eval/                   |              |
|    mean_ep_length       | 250          |
|    mean_reward          | -431         |
| time/                   |              |
|    total_timesteps      | 560000       |
| train/                  |              |
|    approx_kl            | 0.0040130513 |
|    clip_fraction        | 0.029        |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.118       |
|    explained_variance   | 0.959        |
|    learning_rate        | 0.0001       |
|    loss                 | 154          |
|    n_updates            | 136          |
|    policy_gradient_loss | 0.00087      |
|    value_loss           | 233          |
------------------------------------------
[2K---------------------------------â”â”â”[0m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m573,392/10,000,000 [0m [ [33m0:20:56[0m < [36m3:18:36[0m , [31m791 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | -417     |
| time/              |          |
|    fps             | 456      |
|    iterations      | 35       |
|    time_elapsed    | 1256     |
|    total_timesteps | 573440   |
---------------------------------
[2K----------------------------------------[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m589,752/10,000,000 [0m [ [33m0:21:33[0m < [36m4:47:20[0m , [31m546 it/s[0m ]
| rollout/                |            |
|    ep_len_mean          | 142        |
|    ep_rew_mean          | -288       |
| time/                   |            |
|    fps                  | 455        |
|    iterations           | 36         |
|    time_elapsed         | 1294       |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.12272054 |
|    clip_fraction        | 0.0457     |
|    clip_range           | 0.1        |
|    entropy_loss         | -0.101     |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.0001     |
|    loss                 | 121        |
|    n_updates            | 140        |
|    policy_gradient_loss | 0.00109    |
|    value_loss           | 175        |
----------------------------------------
[2K-------------------------------------------8;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m606,168/10,000,000 [0m [ [33m0:22:11[0m < [36m4:44:09[0m , [31m551 it/s[0m ]
| rollout/                |               |
|    ep_len_mean          | 135           |
|    ep_rew_mean          | -279          |
| time/                   |               |
|    fps                  | 455           |
|    iterations           | 37            |
|    time_elapsed         | 1331          |
|    total_timesteps      | 606208        |
| train/                  |               |
|    approx_kl            | 0.00032754912 |
|    clip_fraction        | 0.00127       |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.00864      |
|    explained_variance   | 0.948         |
|    learning_rate        | 0.0001        |
|    loss                 | 65.1          |
|    n_updates            | 144           |
|    policy_gradient_loss | -0.00053      |
|    value_loss           | 94.6          |
-------------------------------------------
[2K-------------------------------------------8;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m622,504/10,000,000 [0m [ [33m0:22:38[0m < [36m4:22:05[0m , [31m596 it/s[0m ]
| rollout/                |               |
|    ep_len_mean          | 145           |
|    ep_rew_mean          | -291          |
| time/                   |               |
|    fps                  | 458           |
|    iterations           | 38            |
|    time_elapsed         | 1358          |
|    total_timesteps      | 622592        |
| train/                  |               |
|    approx_kl            | 2.5398393e-05 |
|    clip_fraction        | 0.00029       |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.00564      |
|    explained_variance   | 0.982         |
|    learning_rate        | 0.0001        |
|    loss                 | 25.9          |
|    n_updates            | 148           |
|    policy_gradient_loss | -0.000158     |
|    value_loss           | 42.6          |
-------------------------------------------
[2K-------------------------------------------38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m638,936/10,000,000 [0m [ [33m0:23:05[0m < [36m4:14:59[0m , [31m612 it/s[0m ]s[0m ]
| rollout/                |               |
|    ep_len_mean          | 133           |
|    ep_rew_mean          | -276          |
| time/                   |               |
|    fps                  | 461           |
|    iterations           | 39            |
|    time_elapsed         | 1385          |
|    total_timesteps      | 638976        |
| train/                  |               |
|    approx_kl            | 4.1725256e-05 |
|    clip_fraction        | 0.000488      |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.00372      |
|    explained_variance   | 0.972         |
|    learning_rate        | 0.0001        |
|    loss                 | 96.3          |
|    n_updates            | 152           |
|    policy_gradient_loss | 0.000224      |
|    value_loss           | 38.2          |
-------------------------------------------
[2KEval num_timesteps=640000, episode_reward=-274.40 +/- 0.00[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m639,912/10,000,000 [0m [ [33m0:23:20[0m < [36m4:18:23[0m , [31m604 it/s[0m ]
[2KEpisode length: 132.00 +/- 0.00â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m639,912/10,000,000 [0m [ [33m0:23:20[0m < [36m4:18:23[0m , [31m604 it/s[0m ]
[2K-------------------------------------------;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m639,912/10,000,000 [0m [ [33m0:23:20[0m < [36m4:18:23[0m , [31m604 it/s[0m ]
| eval/                   |               |
|    mean_ep_length       | 132           |
|    mean_reward          | -274          |
| time/                   |               |
|    total_timesteps      | 640000        |
| train/                  |               |
|    approx_kl            | 0.00042411475 |
|    clip_fraction        | 0.000305      |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.000587     |
|    explained_variance   | 0.992         |
|    learning_rate        | 0.0001        |
|    loss                 | 15.4          |
|    n_updates            | 156           |
|    policy_gradient_loss | 8.41e-05      |
|    value_loss           | 16.3          |
-------------------------------------------
[2KNew best mean reward!;38;114mâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m639,912/10,000,000 [0m [ [33m0:23:20[0m < [36m4:18:23[0m , [31m604 it/s[0m ]
[2K---------------------------------â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m655,248/10,000,000 [0m [ [33m0:23:41[0m < [36m4:36:18[0m , [31m564 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | -275     |
| time/              |          |
|    fps             | 461      |
|    iterations      | 40       |
|    time_elapsed    | 1421     |
|    total_timesteps | 655360   |
---------------------------------
[2K------------------------------------------[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m671,688/10,000,000 [0m [ [33m0:24:12[0m < [36m3:49:33[0m , [31m677 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 132          |
|    ep_rew_mean          | -274         |
| time/                   |              |
|    fps                  | 462          |
|    iterations           | 41           |
|    time_elapsed         | 1452         |
|    total_timesteps      | 671744       |
| train/                  |              |
|    approx_kl            | 6.132759e-06 |
|    clip_fraction        | 0.000183     |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.000691    |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0001       |
|    loss                 | 7.68         |
|    n_updates            | 160          |
|    policy_gradient_loss | -6.33e-05    |
|    value_loss           | 12           |
------------------------------------------
[2K-----------------------------------------[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m688,096/10,000,000 [0m [ [33m0:24:43[0m < [36m3:42:17[0m , [31m698 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 134         |
|    ep_rew_mean          | -276        |
| time/                   |             |
|    fps                  | 463         |
|    iterations           | 42          |
|    time_elapsed         | 1483        |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 8.42227e-06 |
|    clip_fraction        | 3.05e-05    |
|    clip_range           | 0.1         |
|    entropy_loss         | -0.00136    |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0001      |
|    loss                 | 8.01        |
|    n_updates            | 164         |
|    policy_gradient_loss | -2.9e-05    |
|    value_loss           | 17.4        |
-----------------------------------------
[2K------------------------------------------[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m704,416/10,000,000 [0m [ [33m0:25:19[0m < [36m4:42:01[0m , [31m549 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 132          |
|    ep_rew_mean          | -275         |
| time/                   |              |
|    fps                  | 463          |
|    iterations           | 43           |
|    time_elapsed         | 1519         |
|    total_timesteps      | 704512       |
| train/                  |              |
|    approx_kl            | 0.0003267487 |
|    clip_fraction        | 0.000412     |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.00146     |
|    explained_variance   | 0.995        |
|    learning_rate        | 0.0001       |
|    loss                 | 11           |
|    n_updates            | 168          |
|    policy_gradient_loss | -9.7e-05     |
|    value_loss           | 14.5         |
------------------------------------------
[2KEval num_timesteps=720000, episode_reward=-274.40 +/- 0.00mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m719,952/10,000,000 [0m [ [33m0:25:52[0m < [36m4:17:31[0m , [31m601 it/s[0m ]
[2KEpisode length: 132.00 +/- 0.00â”â”[0m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m719,952/10,000,000 [0m [ [33m0:25:52[0m < [36m4:17:31[0m , [31m601 it/s[0m ]
[2K-------------------------------------------;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m719,952/10,000,000 [0m [ [33m0:25:52[0m < [36m4:17:31[0m , [31m601 it/s[0m ]
| eval/                   |               |
|    mean_ep_length       | 132           |
|    mean_reward          | -274          |
| time/                   |               |
|    total_timesteps      | 720000        |
| train/                  |               |
|    approx_kl            | 2.8625233e-05 |
|    clip_fraction        | 6.1e-05       |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.000368     |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0001        |
|    loss                 | 38.7          |
|    n_updates            | 172           |
|    policy_gradient_loss | 5.58e-05      |
|    value_loss           | 16.9          |
-------------------------------------------
[2K---------------------------------â”â”â”â”[0m[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m720,872/10,000,000 [0m [ [33m0:25:53[0m < [36m4:28:19[0m , [31m576 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -274     |
| time/              |          |
|    fps             | 464      |
|    iterations      | 44       |
|    time_elapsed    | 1553     |
|    total_timesteps | 720896   |
---------------------------------
[2K------------------------------------------[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m737,248/10,000,000 [0m [ [33m0:26:20[0m < [36m4:09:23[0m , [31m619 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 132          |
|    ep_rew_mean          | -275         |
| time/                   |              |
|    fps                  | 466          |
|    iterations           | 45           |
|    time_elapsed         | 1580         |
|    total_timesteps      | 737280       |
| train/                  |              |
|    approx_kl            | -4.12183e-09 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.000267    |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0001       |
|    loss                 | 13.2         |
|    n_updates            | 176          |
|    policy_gradient_loss | 1.24e-06     |
|    value_loss           | 5.96         |
------------------------------------------
[2K-------------------------------------------38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m753,592/10,000,000 [0m [ [33m0:26:56[0m < [36m4:34:09[0m , [31m562 it/s[0m ]
| rollout/                |               |
|    ep_len_mean          | 132           |
|    ep_rew_mean          | -274          |
| time/                   |               |
|    fps                  | 466           |
|    iterations           | 46            |
|    time_elapsed         | 1616          |
|    total_timesteps      | 753664        |
| train/                  |               |
|    approx_kl            | 4.9597315e-05 |
|    clip_fraction        | 6.1e-05       |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.000192     |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0001        |
|    loss                 | 3.44          |
|    n_updates            | 180           |
|    policy_gradient_loss | 1.14e-07      |
|    value_loss           | 6.76          |
-------------------------------------------
[2K--------------------------------------------8;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m769,976/10,000,000 [0m [ [33m0:27:33[0m < [36m4:39:46[0m , [31m550 it/s[0m ]
| rollout/                |                |
|    ep_len_mean          | 132            |
|    ep_rew_mean          | -274           |
| time/                   |                |
|    fps                  | 465            |
|    iterations           | 47             |
|    time_elapsed         | 1653           |
|    total_timesteps      | 770048         |
| train/                  |                |
|    approx_kl            | -3.5288394e-09 |
|    clip_fraction        | 0              |
|    clip_range           | 0.1            |
|    entropy_loss         | -0.000167      |
|    explained_variance   | 0.999          |
|    learning_rate        | 0.0001         |
|    loss                 | 3.2            |
|    n_updates            | 184            |
|    policy_gradient_loss | -1.81e-06      |
|    value_loss           | 5.65           |
--------------------------------------------
[2K------------------------------------------[38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m786,376/10,000,000 [0m [ [33m0:28:09[0m < [36m4:33:01[0m , [31m562 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 132          |
|    ep_rew_mean          | -274         |
| time/                   |              |
|    fps                  | 465          |
|    iterations           | 48           |
|    time_elapsed         | 1690         |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 8.767529e-09 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.000285    |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0001       |
|    loss                 | 20.7         |
|    n_updates            | 188          |
|    policy_gradient_loss | -4.55e-06    |
|    value_loss           | 9.57         |
------------------------------------------
[2KTraceback (most recent call last):â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]s[0m ]
[2K  File "C:\Users\User\Desktop\Project-PML-Pong\Part_3\main_aina.py", line 268, in <module>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
    model_path = train_model()
[2K  File "C:\Users\User\Desktop\Project-PML-Pong\Part_3\main_aina.py", line 149, in train_modelâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
    model.learn(
    ~~~~~~~~~~~^
        total_timesteps=config["total_timesteps"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        callback=callback_list,
        ^^^^^^^^^^^^^^^^^^^^^^^
        progress_bar=True
        ^^^^^^^^^^^^^^^^^
    )
    ^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\ppo\ppo.py", line 311, in learn
    return super().learn(
           ~~~~~~~~~~~~~^
        total_timesteps=total_timesteps,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        progress_bar=progress_bar,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 224, in collect_rollouts
    if not callback.on_step():
           ~~~~~~~~~~~~~~~~^^
[2K  File  8%[0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\callbacks.py", line 114, in on_step
    return self._on_step()
           ~~~~~~~~~~~~~^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\callbacks.py", line 223, in _on_step
    continue_training = callback.on_step() and continue_training
                        ~~~~~~~~~~~~~~~~^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\callbacks.py", line 114, in on_step
    return self._on_step()
           ~~~~~~~~~~~~~^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\callbacks.py", line 223, in _on_step
    continue_training = callback.on_step() and continue_training
                        ~~~~~~~~~~~~~~~~^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\callbacks.py", line 114, in on_step
    return self._on_step()
           ~~~~~~~~~~~~~^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\callbacks.py", line 464, in _on_step
    episode_rewards, episode_lengths = evaluate_policy(
                                       ~~~~~~~~~~~~~~~^
        self.model,
        ^^^^^^^^^^^
    ...<6 lines>...
        callback=self._log_success_callback,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\evaluation.py", line 91, in evaluate_policy
    actions, states = model.predict(
                      ~~~~~~~~~~~~~^
        observations,  # type: ignore[arg-type]
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        deterministic=deterministic,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\base_class.py", line 557, in predict
    return self.policy.predict(observation, state, episode_start, deterministic)
           ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\policies.py", line 368, in predict
    actions = self._predict(obs_tensor, deterministic=deterministic)
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\policies.py", line 717, in _predict
    return self.get_distribution(observation).get_actions(deterministic=deterministic)
           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\policies.py", line 750, in get_distribution
    features = super().extract_features(obs, self.pi_features_extractor)
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\policies.py", line 131, in extract_features
    return features_extractor(preprocessed_obs)
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\stable_baselines3\common\torch_layers.py", line 107, in forward
    return self.linear(self.cnn(observations))
                       ~~~~~~~~^^^^^^^^^^^^^^
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[2K  File  8%[0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
[2K  File [0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
"C:\Users\User\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python3
13\site-packages\torch\nn\modules\container.py", line 244, in forward
    input = module(input)
    ^^^^^
[2KKeyboardInterrupt;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
[35m   8%[0m [38;2;249;38;114mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m799,968/10,000,000 [0m [ [33m0:28:54[0m < [36m4:37:39[0m , [31m552 it/s[0m ]
