>>> Training starts at 2025-11-25 21:51:27.118802
>>> Hyperparameters:
    LR: 0.0001, Batch: 32, Gamma: 0.99
    Epsilon: 1.0 -> 0.01 (decay: 0.995)
    Update freq: 8, Sync freq: 1000
Filling replay buffer...
Buffer filled with 10000 experiences

=== BUFFER DIVERSITY CHECK ===
Sample states shape: (100, 4, 84, 84)
State mean: 0.4036
State std: 0.1905
Unique values check: 56
=== CHECK COMPLETE ===

Training a DQN network with Prioritized Replay Buffer
EPISODE 1 COMPLETED
======================================================================
Total Steps: 10841 | Episode Steps: 841
Episode Reward: -20.00 | Mean Reward: -20.00
Loss: 0.00221 | Epsilon: 1.000


Beta: 0.465


EPISODE 2 COMPLETED
======================================================================
Total Steps: 11771 | Episode Steps: 930
Episode Reward: -21.00 | Mean Reward: -20.50
Loss: 0.00445 | Epsilon: 0.995


Beta: 0.471


EPISODE 3 COMPLETED
======================================================================
Total Steps: 12734 | Episode Steps: 963
Episode Reward: -20.00 | Mean Reward: -20.33
Loss: 0.00611 | Epsilon: 0.990


Beta: 0.476


EPISODE 4 COMPLETED
======================================================================
Total Steps: 13497 | Episode Steps: 763
Episode Reward: -21.00 | Mean Reward: -20.50
Loss: 0.01245 | Epsilon: 0.985


Beta: 0.481


EPISODE 5 COMPLETED
======================================================================
Total Steps: 14322 | Episode Steps: 825
Episode Reward: -21.00 | Mean Reward: -20.60
Loss: 0.02143 | Epsilon: 0.980


Beta: 0.486


EPISODE 6 COMPLETED
======================================================================
Total Steps: 15170 | Episode Steps: 848
Episode Reward: -21.00 | Mean Reward: -20.67
Loss: 0.02766 | Epsilon: 0.975


Beta: 0.491


EPISODE 7 COMPLETED
======================================================================
Total Steps: 16023 | Episode Steps: 853
Episode Reward: -21.00 | Mean Reward: -20.71
Loss: 0.02603 | Epsilon: 0.970


Beta: 0.496


EPISODE 8 COMPLETED
======================================================================
Total Steps: 17119 | Episode Steps: 1096
Episode Reward: -20.00 | Mean Reward: -20.62
Loss: 0.02632 | Epsilon: 0.966


Beta: 0.503


EPISODE 9 COMPLETED
======================================================================
Total Steps: 18137 | Episode Steps: 1018
Episode Reward: -20.00 | Mean Reward: -20.56
Loss: 0.03002 | Epsilon: 0.961


Beta: 0.509


EPISODE 10 COMPLETED
======================================================================
Total Steps: 18928 | Episode Steps: 791
Episode Reward: -21.00 | Mean Reward: -20.60
Loss: 0.03034 | Epsilon: 0.956


Beta: 0.514


EPISODE 11 COMPLETED
======================================================================
Total Steps: 19805 | Episode Steps: 877
Episode Reward: -21.00 | Mean Reward: -20.64
Loss: 0.02827 | Epsilon: 0.951


Beta: 0.519


EPISODE 12 COMPLETED
======================================================================
Total Steps: 20688 | Episode Steps: 883
Episode Reward: -21.00 | Mean Reward: -20.67
Loss: 0.02504 | Epsilon: 0.946


Beta: 0.524


EPISODE 13 COMPLETED
======================================================================
Total Steps: 21510 | Episode Steps: 822
Episode Reward: -21.00 | Mean Reward: -20.69
Loss: 0.02743 | Epsilon: 0.942


Beta: 0.529


EPISODE 14 COMPLETED
======================================================================
Total Steps: 22382 | Episode Steps: 872
Episode Reward: -20.00 | Mean Reward: -20.64
Loss: 0.02369 | Epsilon: 0.937


Beta: 0.534


EPISODE 15 COMPLETED
======================================================================
Total Steps: 23362 | Episode Steps: 980
Episode Reward: -20.00 | Mean Reward: -20.60
Loss: 0.02427 | Epsilon: 0.932


Beta: 0.540


EPISODE 16 COMPLETED
======================================================================
Total Steps: 24259 | Episode Steps: 897
Episode Reward: -20.00 | Mean Reward: -20.56
Loss: 0.02612 | Epsilon: 0.928


Beta: 0.546


EPISODE 17 COMPLETED
======================================================================
Total Steps: 25319 | Episode Steps: 1060
Episode Reward: -18.00 | Mean Reward: -20.41
Loss: 0.02001 | Epsilon: 0.923


Beta: 0.552


EPISODE 18 COMPLETED
======================================================================
Total Steps: 26142 | Episode Steps: 823
Episode Reward: -21.00 | Mean Reward: -20.44
Loss: 0.01795 | Epsilon: 0.918


Beta: 0.557


EPISODE 19 COMPLETED
======================================================================
Total Steps: 26905 | Episode Steps: 763
Episode Reward: -21.00 | Mean Reward: -20.47
Loss: 0.01791 | Epsilon: 0.914


Beta: 0.561


EPISODE 20 COMPLETED
======================================================================
Total Steps: 27756 | Episode Steps: 851
Episode Reward: -21.00 | Mean Reward: -20.50
Loss: 0.01600 | Epsilon: 0.909


Beta: 0.567


EPISODE 21 COMPLETED
======================================================================
Total Steps: 28784 | Episode Steps: 1028
Episode Reward: -20.00 | Mean Reward: -20.48
Loss: 0.01403 | Epsilon: 0.905


Beta: 0.573


EPISODE 22 COMPLETED
======================================================================
Total Steps: 29663 | Episode Steps: 879
Episode Reward: -21.00 | Mean Reward: -20.50
Loss: 0.01298 | Epsilon: 0.900


Beta: 0.578


EPISODE 23 COMPLETED
======================================================================
Total Steps: 30445 | Episode Steps: 782
Episode Reward: -21.00 | Mean Reward: -20.52
Loss: 0.01339 | Epsilon: 0.896


Beta: 0.583


EPISODE 24 COMPLETED
======================================================================
Total Steps: 31391 | Episode Steps: 946
Episode Reward: -20.00 | Mean Reward: -20.50
Loss: 0.01364 | Epsilon: 0.891


Beta: 0.588


EPISODE 25 COMPLETED
======================================================================
Total Steps: 32257 | Episode Steps: 866
Episode Reward: -20.00 | Mean Reward: -20.48
Loss: 0.01245 | Epsilon: 0.887


Beta: 0.594


EPISODE 26 COMPLETED
======================================================================
Total Steps: 33278 | Episode Steps: 1021
Episode Reward: -20.00 | Mean Reward: -20.46
Loss: 0.01061 | Epsilon: 0.882


Beta: 0.600


EPISODE 27 COMPLETED
======================================================================
Total Steps: 34101 | Episode Steps: 823
Episode Reward: -21.00 | Mean Reward: -20.48
Loss: 0.01106 | Epsilon: 0.878


Beta: 0.605


EPISODE 28 COMPLETED
======================================================================
Total Steps: 35127 | Episode Steps: 1026
Episode Reward: -21.00 | Mean Reward: -20.50
Loss: 0.00903 | Epsilon: 0.873


Beta: 0.611


EPISODE 29 COMPLETED
======================================================================
Total Steps: 36058 | Episode Steps: 931
Episode Reward: -20.00 | Mean Reward: -20.48
Loss: 0.00826 | Epsilon: 0.869


Beta: 0.616


EPISODE 30 COMPLETED
======================================================================
Total Steps: 36911 | Episode Steps: 853
Episode Reward: -21.00 | Mean Reward: -20.50
Loss: 0.00840 | Epsilon: 0.865


Beta: 0.621


EPISODE 31 COMPLETED
======================================================================
Total Steps: 37721 | Episode Steps: 810
Episode Reward: -21.00 | Mean Reward: -20.52
Loss: 0.00813 | Epsilon: 0.860


Beta: 0.626


EPISODE 32 COMPLETED
======================================================================
Total Steps: 38533 | Episode Steps: 812
Episode Reward: -21.00 | Mean Reward: -20.53
Loss: 0.00813 | Epsilon: 0.856


Beta: 0.631


EPISODE 33 COMPLETED
======================================================================
Total Steps: 39524 | Episode Steps: 991
Episode Reward: -20.00 | Mean Reward: -20.52
Loss: 0.00787 | Epsilon: 0.852


Beta: 0.637


EPISODE 34 COMPLETED
======================================================================
Total Steps: 40343 | Episode Steps: 819
Episode Reward: -21.00 | Mean Reward: -20.53
Loss: 0.00779 | Epsilon: 0.848


Beta: 0.642


EPISODE 35 COMPLETED
======================================================================
Total Steps: 41286 | Episode Steps: 943
Episode Reward: -21.00 | Mean Reward: -20.54
Loss: 0.00714 | Epsilon: 0.843


Beta: 0.648


EPISODE 36 COMPLETED
======================================================================
Total Steps: 42267 | Episode Steps: 981
Episode Reward: -20.00 | Mean Reward: -20.53
Loss: 0.00705 | Epsilon: 0.839


Beta: 0.654


EPISODE 37 COMPLETED
======================================================================
Total Steps: 43108 | Episode Steps: 841
Episode Reward: -20.00 | Mean Reward: -20.51
Loss: 0.00713 | Epsilon: 0.835


Beta: 0.659


EPISODE 38 COMPLETED
======================================================================
Total Steps: 43945 | Episode Steps: 837
Episode Reward: -21.00 | Mean Reward: -20.53
Loss: 0.00735 | Epsilon: 0.831


Beta: 0.664


EPISODE 39 COMPLETED
======================================================================
Total Steps: 44816 | Episode Steps: 871
Episode Reward: -21.00 | Mean Reward: -20.54
Loss: 0.00757 | Epsilon: 0.827


Beta: 0.669


EPISODE 40 COMPLETED
======================================================================
Total Steps: 46019 | Episode Steps: 1203
Episode Reward: -19.00 | Mean Reward: -20.50
Loss: 0.00728 | Epsilon: 0.822


Beta: 0.676


EPISODE 41 COMPLETED
======================================================================
Total Steps: 46921 | Episode Steps: 902
Episode Reward: -20.00 | Mean Reward: -20.49
Loss: 0.00847 | Epsilon: 0.818


Beta: 0.682


EPISODE 42 COMPLETED
======================================================================
Total Steps: 47791 | Episode Steps: 870
Episode Reward: -20.00 | Mean Reward: -20.48
Loss: 0.00694 | Epsilon: 0.814


Beta: 0.687


EPISODE 43 COMPLETED
======================================================================
Total Steps: 48750 | Episode Steps: 959
Episode Reward: -21.00 | Mean Reward: -20.49
Loss: 0.00706 | Epsilon: 0.810


Beta: 0.692


EPISODE 44 COMPLETED
======================================================================
Total Steps: 49798 | Episode Steps: 1048
Episode Reward: -20.00 | Mean Reward: -20.48
Loss: 0.00706 | Epsilon: 0.806


Beta: 0.699


EPISODE 45 COMPLETED
======================================================================
Total Steps: 50896 | Episode Steps: 1098
Episode Reward: -20.00 | Mean Reward: -20.47
Loss: 0.00621 | Epsilon: 0.802


Beta: 0.705


EPISODE 46 COMPLETED
======================================================================
Total Steps: 51785 | Episode Steps: 889
Episode Reward: -20.00 | Mean Reward: -20.46
Loss: 0.00559 | Epsilon: 0.798


Beta: 0.711


EPISODE 47 COMPLETED
======================================================================
Total Steps: 52696 | Episode Steps: 911
Episode Reward: -21.00 | Mean Reward: -20.47
Loss: 0.00585 | Epsilon: 0.794


Beta: 0.716


EPISODE 48 COMPLETED
======================================================================
Total Steps: 53748 | Episode Steps: 1052
Episode Reward: -19.00 | Mean Reward: -20.44
Loss: 0.00579 | Epsilon: 0.790


Beta: 0.722


EPISODE 49 COMPLETED
======================================================================
Total Steps: 54627 | Episode Steps: 879
Episode Reward: -21.00 | Mean Reward: -20.45
Loss: 0.00543 | Epsilon: 0.786


Beta: 0.728


EPISODE 50 COMPLETED
======================================================================
Total Steps: 55529 | Episode Steps: 902
Episode Reward: -20.00 | Mean Reward: -20.44
Loss: 0.00595 | Epsilon: 0.782


Beta: 0.733


Checkpoint saved: checkpoints\checkpoint_ep_50.pt
Removed old checkpoint: checkpoints\checkpoint_ep_1100.pt
C:\Users\ainav\OneDrive\Documents\Uni\4th_year\1st_semester\paradigms_ml\project\Project-PML-Pong\Part_1\functions\Agent.py:413: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  best_checkpoint = torch.load(best_path)
Traceback (most recent call last):
  File "C:\Users\ainav\OneDrive\Documents\Uni\4th_year\1st_semester\paradigms_ml\project\Project-PML-Pong\Part_1\main.py", line 118, in <module>
    agent.train(gamma=GAMMA, max_episodes=MAX_EPISODES,
  File "C:\Users\ainav\OneDrive\Documents\Uni\4th_year\1st_semester\paradigms_ml\project\Project-PML-Pong\Part_1\functions\Agent.py", line 183, in train
    self.save_N_checkpoints(episode, save_dir, keep_last_n=5)
  File "C:\Users\ainav\OneDrive\Documents\Uni\4th_year\1st_semester\paradigms_ml\project\Project-PML-Pong\Part_1\functions\Agent.py", line 413, in save_N_checkpoints
    best_checkpoint = torch.load(best_path)
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\serialization.py", line 1360, in load
    return _load(
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\serialization.py", line 1848, in _load
    result = unpickler.load()
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\serialization.py", line 1812, in persistent_load
    typed_storage = load_tensor(
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\serialization.py", line 1784, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\serialization.py", line 601, in default_restore_location
    result = fn(storage, location)
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\serialization.py", line 539, in _deserialize
    device = _validate_device(location, backend_name)
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\serialization.py", line 508, in _validate_device
    raise RuntimeError(
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
