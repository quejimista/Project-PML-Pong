diff --git a/Part_3/functions/__pycache__/preprocessing.cpython-310.pyc b/Part_3/functions/__pycache__/preprocessing.cpython-310.pyc
index 5257f16..4bc016d 100644
Binary files a/Part_3/functions/__pycache__/preprocessing.cpython-310.pyc and b/Part_3/functions/__pycache__/preprocessing.cpython-310.pyc differ
diff --git a/Part_3/functions/preprocessing.py b/Part_3/functions/preprocessing.py
index 8f1533e..653fabc 100644
--- a/Part_3/functions/preprocessing.py
+++ b/Part_3/functions/preprocessing.py
@@ -7,7 +7,7 @@ from gymnasium.wrappers import ResizeObservation, GrayscaleObservation, FrameSta
 import ale_py
 import matplotlib.pyplot as plt
 from gymnasium.wrappers import TimeLimit
-
+from stable_baselines3.common.monitor import Monitor
 class GrayScaleObs(ObservationWrapper):
     def __init__(self, env):
         super().__init__(env)
@@ -160,6 +160,7 @@ def make_env(env_name = "ALE/Skiing-v5", render=None, verbose = False):
     # env = ScaledFloatFrame(env)
     # print("ScaledFloatFrame     :", env.observation_space.shape)
     env = TimeLimit(env, max_episode_steps=25000)
+    env = Monitor(env)
 
     return env
 
@@ -278,7 +279,7 @@ def save_plot(snapshots):
 
 
 if __name__ == "__main__":
-    capture_and_save_pipeline()
+    # capture_and_save_pipeline()
 
     #simulate a game to see how it moves
     env = make_env("ALE/Skiing-v5", render='human')
diff --git a/Part_3/main.py b/Part_3/main.py
index 12a7324..0ca35a1 100644
--- a/Part_3/main.py
+++ b/Part_3/main.py
@@ -32,7 +32,7 @@ def train_model(env, model_name, thresh):
         model = A2C(config["policy_type"], env, verbose=0, tensorboard_log=f"runs/{run.id}", device=DEVICE)
     elif model_name == "ppo":
         model = PPO("CnnPolicy", env, verbose=1, device=DEVICE, n_steps=4096, 
-                    batch_size=4096,gamma=0.9999)
+                    batch_size=4096,gamma=0.9999, ent_coef=0.01)
     else:
         print("Error, unknown model ({})".format(model_name))
         return None
@@ -50,7 +50,7 @@ def train_model(env, model_name, thresh):
         best_model_save_path=f"{config['export_path']}best_{model_name}", #save best model
         log_path=f"./logs/{model_name}",
         eval_freq=5000, #eval every 5000 steps
-        deterministic=True, 
+        deterministic=False, 
         render=False,
         verbose=1
     )
@@ -109,6 +109,7 @@ config = {
     "total_timesteps": 10000000,
     "env_name": "ALE/Skiing-v5",
     "export_path": "./exports/",
+    "env_name": "ALE/Skiing-v5"
 }
 
 
@@ -120,7 +121,7 @@ env = make_env()
 thresh = env.spec.reward_threshold if env.spec.reward_threshold is not None else -5000
 # create environment
 make_env(verbose = True) #to show prints only one
-env = DummyVecEnv([lambda: make_env(env_name) for _ in range(8)])
+env = DummyVecEnv([lambda: make_env(config["env_name"]) for _ in range(8)])
 
 
 # Training process
diff --git a/Part_3/main_aina.py b/Part_3/main_aina.py
index 8d93aae..d870fd2 100644
--- a/Part_3/main_aina.py
+++ b/Part_3/main_aina.py
@@ -1,5 +1,6 @@
 import wandb
 import torch
+import os
 from datetime import datetime
 from stable_baselines3 import PPO
 from stable_baselines3.common.vec_env import SubprocVecEnv
@@ -9,6 +10,7 @@ from stable_baselines3.common.evaluation import evaluate_policy
 from functions.preprocessing_aina import make_env
 
 
+
 # ------------------ DEVICE ------------------
 DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
 print(f"Using device: {DEVICE}")
@@ -91,14 +93,15 @@ def train_model():
     # Create evaluation environment
     eval_env = make_env(config["env_name"])
     eval_env = Monitor(eval_env)
-    
+    base_path = os.path.abspath(os.getcwd())
+    log_path = os.path.join(base_path,"runs", run.id)
     # Create PPO model with optimized hyperparameters
     model = PPO(
         config["policy_type"],
         env,
         verbose=1,
         device=DEVICE,
-        tensorboard_log=f"runs/{run.id}",
+        tensorboard_log=log_path,
         
         # Training hyperparameters
         n_steps=config["n_steps"],
diff --git a/exports/best_ppo/best_model.zip b/exports/best_ppo/best_model.zip
index f9ae7d6..e6a8bf3 100644
Binary files a/exports/best_ppo/best_model.zip and b/exports/best_ppo/best_model.zip differ
diff --git a/logs/ppo/evaluations.npz b/logs/ppo/evaluations.npz
index 5e0422d..8f7951a 100644
Binary files a/logs/ppo/evaluations.npz and b/logs/ppo/evaluations.npz differ
