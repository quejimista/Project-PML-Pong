
============================================================
Training PPO on ALE/Skiing-v5
============================================================

Saving TensorBoard logs to: C:/Pong_part_3/logs
Using cuda device

Model architecture:
ActorCriticCnnPolicy(
  (features_extractor): NatureCNN(
    (cnn): Sequential(
      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))
      (1): ReLU()
      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): ReLU()
      (6): Flatten(start_dim=1, end_dim=-1)
    )
    (linear): Sequential(
      (0): Linear(in_features=3136, out_features=512, bias=True)
      (1): ReLU()
    )
  )
  (pi_features_extractor): NatureCNN(
    (cnn): Sequential(
      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))
      (1): ReLU()
      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): ReLU()
      (6): Flatten(start_dim=1, end_dim=-1)
    )
    (linear): Sequential(
      (0): Linear(in_features=3136, out_features=512, bias=True)
      (1): ReLU()
    )
  )
  (vf_features_extractor): NatureCNN(
    (cnn): Sequential(
      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))
      (1): ReLU()
      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): ReLU()
      (6): Flatten(start_dim=1, end_dim=-1)
    )
    (linear): Sequential(
      (0): Linear(in_features=3136, out_features=512, bias=True)
      (1): ReLU()
    )
  )
  (mlp_extractor): MlpExtractor(
    (policy_net): Sequential()
    (value_net): Sequential()
  )
  (action_net): Linear(in_features=512, out_features=3, bias=True)
  (value_net): Linear(in_features=512, out_features=1, bias=True)
)

Starting training for 10,000,000 timesteps...
This equals 610 updates
Evaluation every 1250 updates
wandb: WARNING Found log directory outside of given root_logdir, dropping given root_logdir for event file in C:/Pong_part_3/logs\PPO_30

Logging to C:/Pong_part_3/logs\PPO_30
C:\Users\Iv√°n\AppData\Local\Programs\Python\Python310\lib\site-packages\stable_baselines3\common\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x00000241B839EEF0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000002418B525B40>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
wandb: WARNING Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.5e+03 |
| time/              |          |
|    fps             | 978      |
|    iterations      | 1        |
|    time_elapsed    | 16       |
|    total_timesteps | 16384    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 853       |
|    iterations           | 2         |
|    time_elapsed         | 38        |
|    total_timesteps      | 32768     |
| train/                  |           |
|    approx_kl            | 6.6185684 |
|    clip_fraction        | 0.92      |
|    clip_range           | 0.1       |
|    entropy_loss         | -0.311    |
|    explained_variance   | 1.53e-05  |
|    learning_rate        | 0.0003    |
|    loss                 | 7.2e+03   |
|    n_updates            | 4         |
|    policy_gradient_loss | 0.381     |
|    value_loss           | 7.31e+03  |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76            |
|    ep_rew_mean          | -1.53e+03     |
| time/                   |               |
|    fps                  | 815           |
|    iterations           | 3             |
|    time_elapsed         | 60            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 0.00021193436 |
|    clip_fraction        | 0.00139       |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.0039       |
|    explained_variance   | 0.00484       |
|    learning_rate        | 0.0003        |
|    loss                 | 377           |
|    n_updates            | 8             |
|    policy_gradient_loss | 7.79e-05      |
|    value_loss           | 468           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 76          |
|    ep_rew_mean          | -1.53e+03   |
| time/                   |             |
|    fps                  | 802         |
|    iterations           | 4           |
|    time_elapsed         | 81          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.006881262 |
|    clip_fraction        | 0.000778    |
|    clip_range           | 0.1         |
|    entropy_loss         | -0.0076     |
|    explained_variance   | -0.324      |
|    learning_rate        | 0.0003      |
|    loss                 | 19.3        |
|    n_updates            | 12          |
|    policy_gradient_loss | 0.000522    |
|    value_loss           | 41.1        |
-----------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=80000, episode_reward=-1535.60 +/- 0.00
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.54e+03 |
| time/                   |           |
|    total_timesteps      | 80000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.78e-07 |
|    explained_variance   | -0.12     |
|    learning_rate        | 0.0003    |
|    loss                 | 22.7      |
|    n_updates            | 16        |
|    policy_gradient_loss | -1.68e-09 |
|    value_loss           | 25.2      |
---------------------------------------
New best mean reward!
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 768       |
|    iterations      | 5         |
|    time_elapsed    | 106       |
|    total_timesteps | 81920     |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 770       |
|    iterations           | 6         |
|    time_elapsed         | 127       |
|    total_timesteps      | 98304     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -8.71e-07 |
|    explained_variance   | 0.0148    |
|    learning_rate        | 0.0003    |
|    loss                 | 4.13      |
|    n_updates            | 20        |
|    policy_gradient_loss | -8.04e-09 |
|    value_loss           | 33.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 769       |
|    iterations           | 7         |
|    time_elapsed         | 149       |
|    total_timesteps      | 114688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.03e-06 |
|    explained_variance   | 0.121     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.51      |
|    n_updates            | 24        |
|    policy_gradient_loss | 1.98e-08  |
|    value_loss           | 23.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 767       |
|    iterations           | 8         |
|    time_elapsed         | 170       |
|    total_timesteps      | 131072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.16e-06 |
|    explained_variance   | 0.196     |
|    learning_rate        | 0.0003    |
|    loss                 | 43.6      |
|    n_updates            | 28        |
|    policy_gradient_loss | -5.42e-09 |
|    value_loss           | 20.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 769       |
|    iterations           | 9         |
|    time_elapsed         | 191       |
|    total_timesteps      | 147456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -9.73e-07 |
|    explained_variance   | 0.209     |
|    learning_rate        | 0.0003    |
|    loss                 | 25.9      |
|    n_updates            | 32        |
|    policy_gradient_loss | 2.57e-09  |
|    value_loss           | 15.8      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=160000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 160000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.23e-06 |
|    explained_variance   | 0.327     |
|    learning_rate        | 0.0003    |
|    loss                 | 29.5      |
|    n_updates            | 36        |
|    policy_gradient_loss | -3.57e-09 |
|    value_loss           | 13.7      |
---------------------------------------
New best mean reward!
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 752       |
|    iterations      | 10        |
|    time_elapsed    | 217       |
|    total_timesteps | 163840    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 749       |
|    iterations           | 11        |
|    time_elapsed         | 240       |
|    total_timesteps      | 180224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.13e-06 |
|    explained_variance   | 0.31      |
|    learning_rate        | 0.0003    |
|    loss                 | 6.54      |
|    n_updates            | 40        |
|    policy_gradient_loss | -5.37e-10 |
|    value_loss           | 13.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 751       |
|    iterations           | 12        |
|    time_elapsed         | 261       |
|    total_timesteps      | 196608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.01e-06 |
|    explained_variance   | 0.296     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.25      |
|    n_updates            | 44        |
|    policy_gradient_loss | -2.15e-09 |
|    value_loss           | 15.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 752       |
|    iterations           | 13        |
|    time_elapsed         | 283       |
|    total_timesteps      | 212992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.29e-06 |
|    explained_variance   | 0.341     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.99      |
|    n_updates            | 48        |
|    policy_gradient_loss | -1.16e-09 |
|    value_loss           | 14.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 753       |
|    iterations           | 14        |
|    time_elapsed         | 304       |
|    total_timesteps      | 229376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.56e-06 |
|    explained_variance   | 0.336     |
|    learning_rate        | 0.0003    |
|    loss                 | 12.5      |
|    n_updates            | 52        |
|    policy_gradient_loss | 2.01e-09  |
|    value_loss           | 24.5      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=240000, episode_reward=-1534.95 +/- 1.95
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 240000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.46e-06 |
|    explained_variance   | 0.35      |
|    learning_rate        | 0.0003    |
|    loss                 | 5.57      |
|    n_updates            | 56        |
|    policy_gradient_loss | 3.82e-09  |
|    value_loss           | 15        |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 746       |
|    iterations      | 15        |
|    time_elapsed    | 329       |
|    total_timesteps | 245760    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 16        |
|    time_elapsed         | 350       |
|    total_timesteps      | 262144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.63e-06 |
|    explained_variance   | 0.379     |
|    learning_rate        | 0.0003    |
|    loss                 | 8.58      |
|    n_updates            | 60        |
|    policy_gradient_loss | 1.96e-10  |
|    value_loss           | 20.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 17        |
|    time_elapsed         | 372       |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.44e-06 |
|    explained_variance   | 0.364     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.85      |
|    n_updates            | 64        |
|    policy_gradient_loss | -1.31e-10 |
|    value_loss           | 24        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 18        |
|    time_elapsed         | 394       |
|    total_timesteps      | 294912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.32e-06 |
|    explained_variance   | 0.347     |
|    learning_rate        | 0.0003    |
|    loss                 | 24.4      |
|    n_updates            | 68        |
|    policy_gradient_loss | 5.81e-10  |
|    value_loss           | 22.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 749       |
|    iterations           | 19        |
|    time_elapsed         | 415       |
|    total_timesteps      | 311296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.87e-06 |
|    explained_variance   | 0.457     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.11      |
|    n_updates            | 72        |
|    policy_gradient_loss | 3.03e-10  |
|    value_loss           | 16.4      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=320000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 320000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.84e-06 |
|    explained_variance   | 0.433     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.42      |
|    n_updates            | 76        |
|    policy_gradient_loss | 2.61e-10  |
|    value_loss           | 18.4      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 742       |
|    iterations      | 20        |
|    time_elapsed    | 441       |
|    total_timesteps | 327680    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 744       |
|    iterations           | 21        |
|    time_elapsed         | 462       |
|    total_timesteps      | 344064    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.19e-06 |
|    explained_variance   | 0.537     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.99      |
|    n_updates            | 80        |
|    policy_gradient_loss | 7.63e-09  |
|    value_loss           | 26.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 745       |
|    iterations           | 22        |
|    time_elapsed         | 483       |
|    total_timesteps      | 360448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.39e-06 |
|    explained_variance   | 0.602     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.41      |
|    n_updates            | 84        |
|    policy_gradient_loss | 1.18e-08  |
|    value_loss           | 27.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 23        |
|    time_elapsed         | 504       |
|    total_timesteps      | 376832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.62e-06 |
|    explained_variance   | 0.664     |
|    learning_rate        | 0.0003    |
|    loss                 | 11        |
|    n_updates            | 88        |
|    policy_gradient_loss | -5.94e-08 |
|    value_loss           | 19.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 24        |
|    time_elapsed         | 525       |
|    total_timesteps      | 393216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.64e-06 |
|    explained_variance   | 0.71      |
|    learning_rate        | 0.0003    |
|    loss                 | 13.7      |
|    n_updates            | 92        |
|    policy_gradient_loss | -3.93e-08 |
|    value_loss           | 19.3      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=400000, episode_reward=-1533.65 +/- 2.98
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 400000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.76e-06 |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.0003    |
|    loss                 | 12        |
|    n_updates            | 96        |
|    policy_gradient_loss | -2.95e-08 |
|    value_loss           | 18.6      |
---------------------------------------
New best mean reward!
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 744       |
|    iterations      | 25        |
|    time_elapsed    | 550       |
|    total_timesteps | 409600    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 26        |
|    time_elapsed         | 570       |
|    total_timesteps      | 425984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.84e-06 |
|    explained_variance   | 0.739     |
|    learning_rate        | 0.0003    |
|    loss                 | 10.8      |
|    n_updates            | 100       |
|    policy_gradient_loss | -3.12e-08 |
|    value_loss           | 18.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 27        |
|    time_elapsed         | 592       |
|    total_timesteps      | 442368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.97e-06 |
|    explained_variance   | 0.761     |
|    learning_rate        | 0.0003    |
|    loss                 | 12.2      |
|    n_updates            | 104       |
|    policy_gradient_loss | -2.05e-08 |
|    value_loss           | 17.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 28        |
|    time_elapsed         | 613       |
|    total_timesteps      | 458752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.14e-06 |
|    explained_variance   | 0.783     |
|    learning_rate        | 0.0003    |
|    loss                 | 9.69      |
|    n_updates            | 108       |
|    policy_gradient_loss | -6.81e-09 |
|    value_loss           | 17.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 29        |
|    time_elapsed         | 634       |
|    total_timesteps      | 475136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.28e-06 |
|    explained_variance   | 0.798     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.68      |
|    n_updates            | 112       |
|    policy_gradient_loss | -1.45e-08 |
|    value_loss           | 16.5      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=480000, episode_reward=-1533.65 +/- 2.98
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 480000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.46e-06 |
|    explained_variance   | 0.753     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.8       |
|    n_updates            | 116       |
|    policy_gradient_loss | -1.88e-08 |
|    value_loss           | 16.4      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 745       |
|    iterations      | 30        |
|    time_elapsed    | 659       |
|    total_timesteps | 491520    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 31        |
|    time_elapsed         | 680       |
|    total_timesteps      | 507904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.78e-06 |
|    explained_variance   | 0.765     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.3       |
|    n_updates            | 120       |
|    policy_gradient_loss | 2.74e-09  |
|    value_loss           | 15.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 32        |
|    time_elapsed         | 701       |
|    total_timesteps      | 524288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.05e-06 |
|    explained_variance   | 0.811     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.99      |
|    n_updates            | 124       |
|    policy_gradient_loss | 6.17e-09  |
|    value_loss           | 14.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 33        |
|    time_elapsed         | 723       |
|    total_timesteps      | 540672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.21e-06 |
|    explained_variance   | 0.831     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.97      |
|    n_updates            | 128       |
|    policy_gradient_loss | -1.98e-08 |
|    value_loss           | 14.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 34        |
|    time_elapsed         | 744       |
|    total_timesteps      | 557056    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.49e-06 |
|    explained_variance   | 0.688     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.11      |
|    n_updates            | 132       |
|    policy_gradient_loss | 4.56e-09  |
|    value_loss           | 14.1      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=560000, episode_reward=-1535.60 +/- 0.00
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.54e+03 |
| time/                   |           |
|    total_timesteps      | 560000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.73e-06 |
|    explained_variance   | 0.83      |
|    learning_rate        | 0.0003    |
|    loss                 | 3.26      |
|    n_updates            | 136       |
|    policy_gradient_loss | -1.92e-08 |
|    value_loss           | 13.5      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 745       |
|    iterations      | 35        |
|    time_elapsed    | 769       |
|    total_timesteps | 573440    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 36        |
|    time_elapsed         | 790       |
|    total_timesteps      | 589824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.98e-06 |
|    explained_variance   | 0.849     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.3       |
|    n_updates            | 140       |
|    policy_gradient_loss | 6.96e-09  |
|    value_loss           | 12.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 37        |
|    time_elapsed         | 810       |
|    total_timesteps      | 606208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -5.42e-06 |
|    explained_variance   | 0.87      |
|    learning_rate        | 0.0003    |
|    loss                 | 1.21      |
|    n_updates            | 144       |
|    policy_gradient_loss | 1.76e-08  |
|    value_loss           | 12.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 38        |
|    time_elapsed         | 831       |
|    total_timesteps      | 622592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.2e-06  |
|    explained_variance   | 0.888     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.26      |
|    n_updates            | 148       |
|    policy_gradient_loss | -5.72e-08 |
|    value_loss           | 14        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 749       |
|    iterations           | 39        |
|    time_elapsed         | 852       |
|    total_timesteps      | 638976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.36e-06 |
|    explained_variance   | 0.807     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.84      |
|    n_updates            | 152       |
|    policy_gradient_loss | 4.87e-08  |
|    value_loss           | 12.2      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=640000, episode_reward=-1533.65 +/- 2.98
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 640000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.73e-06 |
|    explained_variance   | 0.895     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.9       |
|    n_updates            | 156       |
|    policy_gradient_loss | 5.58e-08  |
|    value_loss           | 11.6      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 746       |
|    iterations      | 40        |
|    time_elapsed    | 877       |
|    total_timesteps | 655360    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 41        |
|    time_elapsed         | 898       |
|    total_timesteps      | 671744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -7.42e-06 |
|    explained_variance   | 0.893     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.33      |
|    n_updates            | 160       |
|    policy_gradient_loss | 4.12e-08  |
|    value_loss           | 11.7      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76            |
|    ep_rew_mean          | -1.53e+03     |
| time/                   |               |
|    fps                  | 748           |
|    iterations           | 42            |
|    time_elapsed         | 918           |
|    total_timesteps      | 688128        |
| train/                  |               |
|    approx_kl            | -5.820766e-11 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -8.61e-06     |
|    explained_variance   | 0.862         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.393         |
|    n_updates            | 164           |
|    policy_gradient_loss | 2.6e-08       |
|    value_loss           | 11            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76            |
|    ep_rew_mean          | -1.53e+03     |
| time/                   |               |
|    fps                  | 749           |
|    iterations           | 43            |
|    time_elapsed         | 939           |
|    total_timesteps      | 704512        |
| train/                  |               |
|    approx_kl            | -7.239578e-10 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.19e-05     |
|    explained_variance   | 0.867         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.8           |
|    n_updates            | 168           |
|    policy_gradient_loss | 6.25e-08      |
|    value_loss           | 4.29          |
-------------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=720000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 76           |
|    mean_reward          | -1.53e+03    |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | -6.91216e-11 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.64e-05    |
|    explained_variance   | 0.878        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.34         |
|    n_updates            | 172          |
|    policy_gradient_loss | -1.02e-08    |
|    value_loss           | 2.01         |
------------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 747       |
|    iterations      | 44        |
|    time_elapsed    | 964       |
|    total_timesteps | 720896    |
----------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 76             |
|    ep_rew_mean          | -1.53e+03      |
| time/                   |                |
|    fps                  | 748            |
|    iterations           | 45             |
|    time_elapsed         | 985            |
|    total_timesteps      | 737280         |
| train/                  |                |
|    approx_kl            | -4.1927706e-08 |
|    clip_fraction        | 0              |
|    clip_range           | 0.1            |
|    entropy_loss         | -3.12e-05      |
|    explained_variance   | 0.886          |
|    learning_rate        | 0.0003         |
|    loss                 | 2.92           |
|    n_updates            | 176            |
|    policy_gradient_loss | 3e-08          |
|    value_loss           | 2.01           |
--------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 46        |
|    time_elapsed         | 1007      |
|    total_timesteps      | 753664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0.00391   |
|    clip_range           | 0.1       |
|    entropy_loss         | -0.00286  |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.01      |
|    n_updates            | 180       |
|    policy_gradient_loss | 0.00013   |
|    value_loss           | 2.04      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 47        |
|    time_elapsed         | 1028      |
|    total_timesteps      | 770048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.12e-18 |
|    explained_variance   | 0.902     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.28      |
|    n_updates            | 184       |
|    policy_gradient_loss | -4.39e-09 |
|    value_loss           | 1.96      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 48        |
|    time_elapsed         | 1050      |
|    total_timesteps      | 786432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.85e-18 |
|    explained_variance   | 0.901     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.54      |
|    n_updates            | 188       |
|    policy_gradient_loss | 2.8e-09   |
|    value_loss           | 7.29      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=800000, episode_reward=-1533.00 +/- 3.18
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 800000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.84e-18 |
|    explained_variance   | 0.874     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.92      |
|    n_updates            | 192       |
|    policy_gradient_loss | 3.93e-09  |
|    value_loss           | 8.01      |
---------------------------------------
New best mean reward!
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 746       |
|    iterations      | 49        |
|    time_elapsed    | 1076      |
|    total_timesteps | 802816    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 50        |
|    time_elapsed         | 1097      |
|    total_timesteps      | 819200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.48e-18 |
|    explained_variance   | 0.841     |
|    learning_rate        | 0.0003    |
|    loss                 | 11        |
|    n_updates            | 196       |
|    policy_gradient_loss | 3.64e-09  |
|    value_loss           | 6.26      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 51        |
|    time_elapsed         | 1119      |
|    total_timesteps      | 835584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.19e-18 |
|    explained_variance   | 0.798     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.05      |
|    n_updates            | 200       |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 5.56      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 52        |
|    time_elapsed         | 1141      |
|    total_timesteps      | 851968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.76e-18 |
|    explained_variance   | 0.873     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.2       |
|    n_updates            | 204       |
|    policy_gradient_loss | -7.77e-10 |
|    value_loss           | 5         |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 53        |
|    time_elapsed         | 1163      |
|    total_timesteps      | 868352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.56e-18 |
|    explained_variance   | 0.784     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.98      |
|    n_updates            | 208       |
|    policy_gradient_loss | -4.64e-09 |
|    value_loss           | 5.58      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=880000, episode_reward=-1534.95 +/- 1.95
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 880000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.97e-18 |
|    explained_variance   | 0.905     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.31      |
|    n_updates            | 212       |
|    policy_gradient_loss | -5.4e-09  |
|    value_loss           | 4.22      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 744       |
|    iterations      | 54        |
|    time_elapsed    | 1187      |
|    total_timesteps | 884736    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 745       |
|    iterations           | 55        |
|    time_elapsed         | 1208      |
|    total_timesteps      | 901120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.05e-18 |
|    explained_variance   | 0.829     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.39      |
|    n_updates            | 216       |
|    policy_gradient_loss | -3.26e-10 |
|    value_loss           | 5.05      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 745       |
|    iterations           | 56        |
|    time_elapsed         | 1230      |
|    total_timesteps      | 917504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.14e-18 |
|    explained_variance   | 0.851     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.55      |
|    n_updates            | 220       |
|    policy_gradient_loss | -3.38e-10 |
|    value_loss           | 2.67      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 57        |
|    time_elapsed         | 1251      |
|    total_timesteps      | 933888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.78e-18 |
|    explained_variance   | 0.858     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.764     |
|    n_updates            | 224       |
|    policy_gradient_loss | 7.44e-10  |
|    value_loss           | 2.23      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 58        |
|    time_elapsed         | 1272      |
|    total_timesteps      | 950272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.9e-18  |
|    explained_variance   | 0.862     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.16      |
|    n_updates            | 228       |
|    policy_gradient_loss | -8.42e-10 |
|    value_loss           | 2         |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=960000, episode_reward=-1533.65 +/- 2.98
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 960000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.96e-18 |
|    explained_variance   | 0.873     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.09      |
|    n_updates            | 232       |
|    policy_gradient_loss | -9.34e-10 |
|    value_loss           | 1.81      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 744       |
|    iterations      | 59        |
|    time_elapsed    | 1297      |
|    total_timesteps | 966656    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 745       |
|    iterations           | 60        |
|    time_elapsed         | 1318      |
|    total_timesteps      | 983040    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.31e-18 |
|    explained_variance   | 0.879     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.32      |
|    n_updates            | 236       |
|    policy_gradient_loss | -1.75e-09 |
|    value_loss           | 1.84      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 61        |
|    time_elapsed         | 1339      |
|    total_timesteps      | 999424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.72e-18 |
|    explained_variance   | 0.89      |
|    learning_rate        | 0.0003    |
|    loss                 | 3.7       |
|    n_updates            | 240       |
|    policy_gradient_loss | 3.62e-09  |
|    value_loss           | 1.91      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 62        |
|    time_elapsed         | 1360      |
|    total_timesteps      | 1015808   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.19e-18 |
|    explained_variance   | 0.9       |
|    learning_rate        | 0.0003    |
|    loss                 | 3.04      |
|    n_updates            | 244       |
|    policy_gradient_loss | -7.36e-09 |
|    value_loss           | 2.09      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 63        |
|    time_elapsed         | 1381      |
|    total_timesteps      | 1032192   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.23e-18 |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.08      |
|    n_updates            | 248       |
|    policy_gradient_loss | -8.35e-09 |
|    value_loss           | 2.02      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1040000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1040000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.27e-18 |
|    explained_variance   | 0.903     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.94      |
|    n_updates            | 252       |
|    policy_gradient_loss | 5.31e-10  |
|    value_loss           | 2.12      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 745       |
|    iterations      | 64        |
|    time_elapsed    | 1406      |
|    total_timesteps | 1048576   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 65        |
|    time_elapsed         | 1426      |
|    total_timesteps      | 1064960   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -5.51e-18 |
|    explained_variance   | 0.904     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.29      |
|    n_updates            | 256       |
|    policy_gradient_loss | -1.52e-09 |
|    value_loss           | 4.06      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 66        |
|    time_elapsed         | 1447      |
|    total_timesteps      | 1081344   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.66e-18 |
|    explained_variance   | 0.742     |
|    learning_rate        | 0.0003    |
|    loss                 | 17.1      |
|    n_updates            | 260       |
|    policy_gradient_loss | -2.92e-09 |
|    value_loss           | 10.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 67        |
|    time_elapsed         | 1469      |
|    total_timesteps      | 1097728   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.27e-18 |
|    explained_variance   | 0.86      |
|    learning_rate        | 0.0003    |
|    loss                 | 7.5       |
|    n_updates            | 264       |
|    policy_gradient_loss | -5.46e-11 |
|    value_loss           | 6.79      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 68        |
|    time_elapsed         | 1491      |
|    total_timesteps      | 1114112   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -5.28e-18 |
|    explained_variance   | 0.759     |
|    learning_rate        | 0.0003    |
|    loss                 | 13.4      |
|    n_updates            | 268       |
|    policy_gradient_loss | 1.48e-09  |
|    value_loss           | 5.61      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1120000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1120000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -5.2e-18  |
|    explained_variance   | 0.865     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.54      |
|    n_updates            | 272       |
|    policy_gradient_loss | -1.01e-09 |
|    value_loss           | 4.13      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 745       |
|    iterations      | 69        |
|    time_elapsed    | 1516      |
|    total_timesteps | 1130496   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 70        |
|    time_elapsed         | 1536      |
|    total_timesteps      | 1146880   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -5.79e-18 |
|    explained_variance   | 0.89      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.8       |
|    n_updates            | 276       |
|    policy_gradient_loss | 4.33e-09  |
|    value_loss           | 3.77      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 71        |
|    time_elapsed         | 1557      |
|    total_timesteps      | 1163264   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.62e-18 |
|    explained_variance   | 0.8       |
|    learning_rate        | 0.0003    |
|    loss                 | 4.64      |
|    n_updates            | 280       |
|    policy_gradient_loss | 1.7e-09   |
|    value_loss           | 3.91      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 72        |
|    time_elapsed         | 1579      |
|    total_timesteps      | 1179648   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.19e-18 |
|    explained_variance   | 0.837     |
|    learning_rate        | 0.0003    |
|    loss                 | 15.2      |
|    n_updates            | 284       |
|    policy_gradient_loss | -8.69e-10 |
|    value_loss           | 10.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 73        |
|    time_elapsed         | 1600      |
|    total_timesteps      | 1196032   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -5.28e-18 |
|    explained_variance   | 0.792     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.92      |
|    n_updates            | 288       |
|    policy_gradient_loss | 2.39e-09  |
|    value_loss           | 9.69      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1200000, episode_reward=-1534.95 +/- 1.95
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1200000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -5.89e-18 |
|    explained_variance   | 0.808     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.36      |
|    n_updates            | 292       |
|    policy_gradient_loss | -2.81e-10 |
|    value_loss           | 9.73      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 746       |
|    iterations      | 74        |
|    time_elapsed    | 1624      |
|    total_timesteps | 1212416   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 75        |
|    time_elapsed         | 1645      |
|    total_timesteps      | 1228800   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.97e-18 |
|    explained_variance   | 0.823     |
|    learning_rate        | 0.0003    |
|    loss                 | 19.7      |
|    n_updates            | 296       |
|    policy_gradient_loss | 9.33e-10  |
|    value_loss           | 9.87      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 746       |
|    iterations           | 76        |
|    time_elapsed         | 1666      |
|    total_timesteps      | 1245184   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -5.17e-18 |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.0003    |
|    loss                 | 10.3      |
|    n_updates            | 300       |
|    policy_gradient_loss | 8.17e-10  |
|    value_loss           | 10.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 77        |
|    time_elapsed         | 1688      |
|    total_timesteps      | 1261568   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -6.66e-18 |
|    explained_variance   | 0.728     |
|    learning_rate        | 0.0003    |
|    loss                 | 8.62      |
|    n_updates            | 304       |
|    policy_gradient_loss | 1.21e-09  |
|    value_loss           | 8.1       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 78        |
|    time_elapsed         | 1708      |
|    total_timesteps      | 1277952   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -9.88e-18 |
|    explained_variance   | 0.857     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.39      |
|    n_updates            | 308       |
|    policy_gradient_loss | 1.08e-09  |
|    value_loss           | 6.22      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1280000, episode_reward=-1532.35 +/- 3.25
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1280000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -9.5e-18  |
|    explained_variance   | 0.872     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.91      |
|    n_updates            | 312       |
|    policy_gradient_loss | -2.47e-09 |
|    value_loss           | 7.95      |
---------------------------------------
New best mean reward!
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 746       |
|    iterations      | 79        |
|    time_elapsed    | 1733      |
|    total_timesteps | 1294336   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 80        |
|    time_elapsed         | 1753      |
|    total_timesteps      | 1310720   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.16e-17 |
|    explained_variance   | 0.783     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.34      |
|    n_updates            | 316       |
|    policy_gradient_loss | -4.77e-10 |
|    value_loss           | 7.46      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 81        |
|    time_elapsed         | 1774      |
|    total_timesteps      | 1327104   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.11e-17 |
|    explained_variance   | 0.792     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.07      |
|    n_updates            | 320       |
|    policy_gradient_loss | -8.89e-10 |
|    value_loss           | 4.36      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 82        |
|    time_elapsed         | 1795      |
|    total_timesteps      | 1343488   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.17e-17 |
|    explained_variance   | 0.801     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.77      |
|    n_updates            | 324       |
|    policy_gradient_loss | -2.22e-09 |
|    value_loss           | 4.38      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 83        |
|    time_elapsed         | 1816      |
|    total_timesteps      | 1359872   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.21e-17 |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.39      |
|    n_updates            | 328       |
|    policy_gradient_loss | -2.98e-09 |
|    value_loss           | 3.42      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1360000, episode_reward=-1533.65 +/- 2.98
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1360000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.34e-17 |
|    explained_variance   | 0.829     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.88      |
|    n_updates            | 332       |
|    policy_gradient_loss | 3.1e-09   |
|    value_loss           | 4.15      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 747       |
|    iterations      | 84        |
|    time_elapsed    | 1840      |
|    total_timesteps | 1376256   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 85        |
|    time_elapsed         | 1861      |
|    total_timesteps      | 1392640   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.3e-17  |
|    explained_variance   | 0.91      |
|    learning_rate        | 0.0003    |
|    loss                 | 3.64      |
|    n_updates            | 336       |
|    policy_gradient_loss | 4.17e-09  |
|    value_loss           | 3.04      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 86        |
|    time_elapsed         | 1883      |
|    total_timesteps      | 1409024   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.46e-17 |
|    explained_variance   | 0.851     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.43      |
|    n_updates            | 340       |
|    policy_gradient_loss | -8.15e-10 |
|    value_loss           | 6.58      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 748       |
|    iterations           | 87        |
|    time_elapsed         | 1904      |
|    total_timesteps      | 1425408   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.41e-17 |
|    explained_variance   | 0.836     |
|    learning_rate        | 0.0003    |
|    loss                 | 25.7      |
|    n_updates            | 344       |
|    policy_gradient_loss | -1.22e-09 |
|    value_loss           | 4.99      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1440000, episode_reward=-1532.35 +/- 3.25
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1440000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.12e-17 |
|    explained_variance   | 0.693     |
|    learning_rate        | 0.0003    |
|    loss                 | 10.1      |
|    n_updates            | 348       |
|    policy_gradient_loss | 1.09e-09  |
|    value_loss           | 9.52      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 747       |
|    iterations      | 88        |
|    time_elapsed    | 1929      |
|    total_timesteps | 1441792   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 89        |
|    time_elapsed         | 1950      |
|    total_timesteps      | 1458176   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.06e-17 |
|    explained_variance   | 0.727     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.79      |
|    n_updates            | 352       |
|    policy_gradient_loss | 4.94e-09  |
|    value_loss           | 9.13      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 90        |
|    time_elapsed         | 1972      |
|    total_timesteps      | 1474560   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.19e-17 |
|    explained_variance   | 0.742     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.34      |
|    n_updates            | 356       |
|    policy_gradient_loss | -3.73e-10 |
|    value_loss           | 9.04      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 91        |
|    time_elapsed         | 1994      |
|    total_timesteps      | 1490944   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -9.75e-18 |
|    explained_variance   | 0.749     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.52      |
|    n_updates            | 360       |
|    policy_gradient_loss | 2.35e-09  |
|    value_loss           | 6.12      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 747       |
|    iterations           | 92        |
|    time_elapsed         | 2017      |
|    total_timesteps      | 1507328   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -9.96e-18 |
|    explained_variance   | 0.738     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.66      |
|    n_updates            | 364       |
|    policy_gradient_loss | 6.09e-10  |
|    value_loss           | 4.46      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1520000, episode_reward=-1533.00 +/- 3.18
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1520000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.21e-17 |
|    explained_variance   | 0.834     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.43      |
|    n_updates            | 368       |
|    policy_gradient_loss | 1.16e-10  |
|    value_loss           | 3.8       |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 745       |
|    iterations      | 93        |
|    time_elapsed    | 2044      |
|    total_timesteps | 1523712   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 745       |
|    iterations           | 94        |
|    time_elapsed         | 2066      |
|    total_timesteps      | 1540096   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.2e-17  |
|    explained_variance   | 0.853     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.84      |
|    n_updates            | 372       |
|    policy_gradient_loss | -2.21e-10 |
|    value_loss           | 3.53      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 744       |
|    iterations           | 95        |
|    time_elapsed         | 2089      |
|    total_timesteps      | 1556480   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.24e-17 |
|    explained_variance   | 0.869     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.25      |
|    n_updates            | 376       |
|    policy_gradient_loss | -6.59e-10 |
|    value_loss           | 3.17      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 744       |
|    iterations           | 96        |
|    time_elapsed         | 2112      |
|    total_timesteps      | 1572864   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.41e-17 |
|    explained_variance   | 0.792     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.29      |
|    n_updates            | 380       |
|    policy_gradient_loss | 2.4e-09   |
|    value_loss           | 4.24      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 744       |
|    iterations           | 97        |
|    time_elapsed         | 2135      |
|    total_timesteps      | 1589248   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.4e-17  |
|    explained_variance   | 0.87      |
|    learning_rate        | 0.0003    |
|    loss                 | 1.78      |
|    n_updates            | 384       |
|    policy_gradient_loss | -3.15e-09 |
|    value_loss           | 3.01      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1600000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1600000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.37e-17 |
|    explained_variance   | 0.88      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.88      |
|    n_updates            | 388       |
|    policy_gradient_loss | -2.11e-10 |
|    value_loss           | 2.8       |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 742       |
|    iterations      | 98        |
|    time_elapsed    | 2162      |
|    total_timesteps | 1605632   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 742       |
|    iterations           | 99        |
|    time_elapsed         | 2185      |
|    total_timesteps      | 1622016   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.41e-17 |
|    explained_variance   | 0.806     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.61      |
|    n_updates            | 392       |
|    policy_gradient_loss | -3.1e-09  |
|    value_loss           | 3.67      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 741       |
|    iterations           | 100       |
|    time_elapsed         | 2208      |
|    total_timesteps      | 1638400   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.39e-17 |
|    explained_variance   | 0.869     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.88      |
|    n_updates            | 396       |
|    policy_gradient_loss | -1.13e-09 |
|    value_loss           | 2.96      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 741       |
|    iterations           | 101       |
|    time_elapsed         | 2231      |
|    total_timesteps      | 1654784   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.36e-17 |
|    explained_variance   | 0.882     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.32      |
|    n_updates            | 400       |
|    policy_gradient_loss | -4.91e-09 |
|    value_loss           | 2.79      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 741       |
|    iterations           | 102       |
|    time_elapsed         | 2254      |
|    total_timesteps      | 1671168   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.66e-17 |
|    explained_variance   | 0.806     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.33      |
|    n_updates            | 404       |
|    policy_gradient_loss | -8.69e-10 |
|    value_loss           | 3.83      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1680000, episode_reward=-1533.65 +/- 2.98
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1680000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.53e-17 |
|    explained_variance   | 0.87      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.08      |
|    n_updates            | 408       |
|    policy_gradient_loss | -2.63e-09 |
|    value_loss           | 2.99      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 739       |
|    iterations      | 103       |
|    time_elapsed    | 2281      |
|    total_timesteps | 1687552   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 739       |
|    iterations           | 104       |
|    time_elapsed         | 2304      |
|    total_timesteps      | 1703936   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.63e-17 |
|    explained_variance   | 0.879     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.42      |
|    n_updates            | 412       |
|    policy_gradient_loss | 3.78e-09  |
|    value_loss           | 2.88      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 738       |
|    iterations           | 105       |
|    time_elapsed         | 2328      |
|    total_timesteps      | 1720320   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.6e-17  |
|    explained_variance   | 0.82      |
|    learning_rate        | 0.0003    |
|    loss                 | 8.9       |
|    n_updates            | 416       |
|    policy_gradient_loss | 1.05e-10  |
|    value_loss           | 4.2       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 738       |
|    iterations           | 106       |
|    time_elapsed         | 2351      |
|    total_timesteps      | 1736704   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.57e-17 |
|    explained_variance   | 0.886     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.412     |
|    n_updates            | 420       |
|    policy_gradient_loss | 5.22e-09  |
|    value_loss           | 5         |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 738       |
|    iterations           | 107       |
|    time_elapsed         | 2375      |
|    total_timesteps      | 1753088   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.21e-17 |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.3       |
|    n_updates            | 424       |
|    policy_gradient_loss | -5.61e-09 |
|    value_loss           | 5.91      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1760000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1760000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.47e-17 |
|    explained_variance   | 0.937     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.21      |
|    n_updates            | 428       |
|    policy_gradient_loss | 1.59e-08  |
|    value_loss           | 5.83      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 736       |
|    iterations      | 108       |
|    time_elapsed    | 2401      |
|    total_timesteps | 1769472   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 736       |
|    iterations           | 109       |
|    time_elapsed         | 2424      |
|    total_timesteps      | 1785856   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.35e-17 |
|    explained_variance   | 0.935     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.37      |
|    n_updates            | 432       |
|    policy_gradient_loss | 4.29e-10  |
|    value_loss           | 5.58      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 736       |
|    iterations           | 110       |
|    time_elapsed         | 2447      |
|    total_timesteps      | 1802240   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.28e-17 |
|    explained_variance   | 0.934     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.46      |
|    n_updates            | 436       |
|    policy_gradient_loss | -3.32e-09 |
|    value_loss           | 5.46      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 736       |
|    iterations           | 111       |
|    time_elapsed         | 2469      |
|    total_timesteps      | 1818624   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.25e-17 |
|    explained_variance   | 0.935     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.72      |
|    n_updates            | 440       |
|    policy_gradient_loss | 7.53e-09  |
|    value_loss           | 5.41      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 736       |
|    iterations           | 112       |
|    time_elapsed         | 2491      |
|    total_timesteps      | 1835008   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.3e-17  |
|    explained_variance   | 0.934     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.6       |
|    n_updates            | 444       |
|    policy_gradient_loss | -4.28e-09 |
|    value_loss           | 5.32      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1840000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1840000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.46e-17 |
|    explained_variance   | 0.936     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.75      |
|    n_updates            | 448       |
|    policy_gradient_loss | 1.36e-08  |
|    value_loss           | 5.32      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 735       |
|    iterations      | 113       |
|    time_elapsed    | 2517      |
|    total_timesteps | 1851392   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 735       |
|    iterations           | 114       |
|    time_elapsed         | 2539      |
|    total_timesteps      | 1867776   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.4e-17  |
|    explained_variance   | 0.935     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.59      |
|    n_updates            | 452       |
|    policy_gradient_loss | -5.41e-09 |
|    value_loss           | 5.25      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 735       |
|    iterations           | 115       |
|    time_elapsed         | 2560      |
|    total_timesteps      | 1884160   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.71e-17 |
|    explained_variance   | 0.934     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.65      |
|    n_updates            | 456       |
|    policy_gradient_loss | 2.55e-08  |
|    value_loss           | 5.28      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 735       |
|    iterations           | 116       |
|    time_elapsed         | 2582      |
|    total_timesteps      | 1900544   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -4.99e-17 |
|    explained_variance   | 0.932     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.74      |
|    n_updates            | 460       |
|    policy_gradient_loss | -4.08e-09 |
|    value_loss           | 4.56      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 735       |
|    iterations           | 117       |
|    time_elapsed         | 2605      |
|    total_timesteps      | 1916928   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.41e-17 |
|    explained_variance   | 0.894     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.902     |
|    n_updates            | 464       |
|    policy_gradient_loss | -1.2e-09  |
|    value_loss           | 3.17      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=1920000, episode_reward=-1534.95 +/- 1.95
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 1920000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.41e-17 |
|    explained_variance   | 0.818     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.19      |
|    n_updates            | 468       |
|    policy_gradient_loss | -5.89e-10 |
|    value_loss           | 3.68      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 734       |
|    iterations      | 118       |
|    time_elapsed    | 2630      |
|    total_timesteps | 1933312   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 734       |
|    iterations           | 119       |
|    time_elapsed         | 2652      |
|    total_timesteps      | 1949696   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.02e-17 |
|    explained_variance   | 0.818     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.63      |
|    n_updates            | 472       |
|    policy_gradient_loss | -5.49e-10 |
|    value_loss           | 3.93      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 735       |
|    iterations           | 120       |
|    time_elapsed         | 2674      |
|    total_timesteps      | 1966080   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.12e-17 |
|    explained_variance   | 0.824     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.08      |
|    n_updates            | 476       |
|    policy_gradient_loss | -2.4e-09  |
|    value_loss           | 3.05      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 735       |
|    iterations           | 121       |
|    time_elapsed         | 2697      |
|    total_timesteps      | 1982464   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.76e-17 |
|    explained_variance   | 0.801     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.78      |
|    n_updates            | 480       |
|    policy_gradient_loss | -5.83e-10 |
|    value_loss           | 3.36      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 735       |
|    iterations           | 122       |
|    time_elapsed         | 2719      |
|    total_timesteps      | 1998848   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.17e-17 |
|    explained_variance   | 0.799     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.77      |
|    n_updates            | 484       |
|    policy_gradient_loss | -1.68e-09 |
|    value_loss           | 3.66      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=2000000, episode_reward=-1534.95 +/- 1.95
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 2000000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.94e-17 |
|    explained_variance   | 0.875     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.65      |
|    n_updates            | 488       |
|    policy_gradient_loss | 2.46e-10  |
|    value_loss           | 2.63      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 734       |
|    iterations      | 123       |
|    time_elapsed    | 2744      |
|    total_timesteps | 2015232   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 734       |
|    iterations           | 124       |
|    time_elapsed         | 2766      |
|    total_timesteps      | 2031616   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.02e-17 |
|    explained_variance   | 0.803     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.79      |
|    n_updates            | 492       |
|    policy_gradient_loss | -4.99e-10 |
|    value_loss           | 3.67      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 734       |
|    iterations           | 125       |
|    time_elapsed         | 2788      |
|    total_timesteps      | 2048000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -1.91e-17 |
|    explained_variance   | 0.867     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.67      |
|    n_updates            | 496       |
|    policy_gradient_loss | -2.04e-09 |
|    value_loss           | 2.66      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 734       |
|    iterations           | 126       |
|    time_elapsed         | 2811      |
|    total_timesteps      | 2064384   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.04e-17 |
|    explained_variance   | 0.879     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.1       |
|    n_updates            | 500       |
|    policy_gradient_loss | 2.65e-09  |
|    value_loss           | 2.53      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=2080000, episode_reward=-1535.60 +/- 0.00
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.54e+03 |
| time/                   |           |
|    total_timesteps      | 2080000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.12e-17 |
|    explained_variance   | 0.81      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.07      |
|    n_updates            | 504       |
|    policy_gradient_loss | -1.65e-09 |
|    value_loss           | 3.26      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 733       |
|    iterations      | 127       |
|    time_elapsed    | 2836      |
|    total_timesteps | 2080768   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 733       |
|    iterations           | 128       |
|    time_elapsed         | 2858      |
|    total_timesteps      | 2097152   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.21e-17 |
|    explained_variance   | 0.872     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.91      |
|    n_updates            | 508       |
|    policy_gradient_loss | 2.93e-09  |
|    value_loss           | 2.71      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 733       |
|    iterations           | 129       |
|    time_elapsed         | 2880      |
|    total_timesteps      | 2113536   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.08e-17 |
|    explained_variance   | 0.798     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.98      |
|    n_updates            | 512       |
|    policy_gradient_loss | 6.42e-10  |
|    value_loss           | 3.67      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 733       |
|    iterations           | 130       |
|    time_elapsed         | 2902      |
|    total_timesteps      | 2129920   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.14e-17 |
|    explained_variance   | 0.867     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.78      |
|    n_updates            | 516       |
|    policy_gradient_loss | -5.97e-10 |
|    value_loss           | 2.63      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 734       |
|    iterations           | 131       |
|    time_elapsed         | 2924      |
|    total_timesteps      | 2146304   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.29e-17 |
|    explained_variance   | 0.879     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.45      |
|    n_updates            | 520       |
|    policy_gradient_loss | 1.06e-09  |
|    value_loss           | 2.55      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=2160000, episode_reward=-1534.95 +/- 1.95
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 2160000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.68e-17 |
|    explained_variance   | 0.807     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.65      |
|    n_updates            | 524       |
|    policy_gradient_loss | 2.09e-09  |
|    value_loss           | 3.55      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 733       |
|    iterations      | 132       |
|    time_elapsed    | 2949      |
|    total_timesteps | 2162688   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 733       |
|    iterations           | 133       |
|    time_elapsed         | 2971      |
|    total_timesteps      | 2179072   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.37e-17 |
|    explained_variance   | 0.844     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.22      |
|    n_updates            | 528       |
|    policy_gradient_loss | -1.75e-10 |
|    value_loss           | 3.96      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 733       |
|    iterations           | 134       |
|    time_elapsed         | 2993      |
|    total_timesteps      | 2195456   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.52e-17 |
|    explained_variance   | 0.887     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.7       |
|    n_updates            | 532       |
|    policy_gradient_loss | 3.44e-09  |
|    value_loss           | 2.43      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 733       |
|    iterations           | 135       |
|    time_elapsed         | 3015      |
|    total_timesteps      | 2211840   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.36e-17 |
|    explained_variance   | 0.818     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.42      |
|    n_updates            | 536       |
|    policy_gradient_loss | 2.25e-09  |
|    value_loss           | 3.3       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -1.53e+03 |
| time/                   |           |
|    fps                  | 733       |
|    iterations           | 136       |
|    time_elapsed         | 3037      |
|    total_timesteps      | 2228224   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.43e-17 |
|    explained_variance   | 0.878     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.84      |
|    n_updates            | 540       |
|    policy_gradient_loss | -3.37e-10 |
|    value_loss           | 2.49      |
---------------------------------------
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
--- RESET | Flags Iniciales: 32 ---
Eval num_timesteps=2240000, episode_reward=-1534.30 +/- 2.60
Episode length: 76.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 76        |
|    mean_reward          | -1.53e+03 |
| time/                   |           |
|    total_timesteps      | 2240000   |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.1       |
|    entropy_loss         | -2.45e-17 |
|    explained_variance   | 0.812     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.5       |
|    n_updates            | 544       |
|    policy_gradient_loss | 1.36e-09  |
|    value_loss           | 5.41      |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 76        |
|    ep_rew_mean     | -1.53e+03 |
| time/              |           |
|    fps             | 732       |
|    iterations      | 137       |
|    time_elapsed    | 3062      |
|    total_timesteps | 2244608   |
----------------------------------
