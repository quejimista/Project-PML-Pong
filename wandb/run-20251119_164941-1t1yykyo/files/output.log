>>> Training starts at  2025-11-19 16:49:44.492291
Filling replay buffer...
Training...
Traceback (most recent call last):
  File "c:\Users\ainav\OneDrive\Documents\Uni\4th_year\1st_semester\paradigms_ml\project\Project-PML-Pong\Part 1\main.py", line 45, in <module>
    agent.train(gamma=GAMMA, max_episodes=MAX_EPISODES,
  File "c:\Users\ainav\OneDrive\Documents\Uni\4th_year\1st_semester\paradigms_ml\project\Project-PML-Pong\Part 1\functions\Agent.py", line 92, in train
    self.update()
  File "c:\Users\ainav\OneDrive\Documents\Uni\4th_year\1st_semester\paradigms_ml\project\Project-PML-Pong\Part 1\functions\Agent.py", line 190, in update
    self.net.optimizer.step()
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\optim\optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\optim\optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\optim\adam.py", line 223, in step
    adam(
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\optim\optimizer.py", line 154, in maybe_fallback
    return func(*args, **kwargs)
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\optim\adam.py", line 784, in adam
    func(
  File "C:\Users\ainav\anaconda3\envs\project_paradigms\lib\site-packages\torch\optim\adam.py", line 430, in _single_tensor_adam
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt
